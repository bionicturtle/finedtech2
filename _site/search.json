[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To FinEdTech",
    "section": "",
    "text": "Welcome to my data science blog!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/sim-equity-risk-premium/index.html",
    "href": "posts/sim-equity-risk-premium/index.html",
    "title": "Simulating the equity risk premium",
    "section": "",
    "text": "The following implements the implied ERP approach in Professor Damodaran’s post on the The Price of Risk. My intention is to briefly explore its sensitivity to assumptions.\n\nlibrary(tidyverse)\nlibrary(scales)\n\nsolve_for_R &lt;- function(RF, ER_vector, CP_vector, G2, PV) {\n  \n  # Calculate cash flow vector\n  CF_vector &lt;- ER_vector * CP_vector\n  \n  # Define the objective function\n  objective_function &lt;- function(R) {\n    # This is effectively two-stage dividend discount model except the initial stage is explicated\n    # such that there exists no G1 and G2 refers to the subsequent period of growth\n    \n    PV_calculated &lt;- sum(CF_vector[1:5] / (1 + R)^(1:5)) + CF_vector[6] / ((R - G2) * (1 + R)^5)\n    return((PV - PV_calculated)^2)\n  }\n  \n  # Use the optim function to minimize the objective function\n  result &lt;- optim(par = RF, fn = objective_function, method = \"Brent\", lower = -1, upper = 2)\n  \n  return(result$par)\n}\n\nRF &lt;- 0.04 # I have rounded his riskfree rate of 3.97% to 4.00%\nER_vector &lt;- c(217.8, 245.2, 273.7, 295.1, 308.9, 324.9) # A. Damodaran's earnings vector\nCP_vector &lt;- c(0.84, 0.82, 0.80, 0.78, 0.77, 0.77) # Cash payout ratios\nG2 &lt;- 0.04 # His model sets the stable growth equal to the RF rate\nPV &lt;- 4600 # I rounded 4588.96 to 4,600\n\nimplied_equity &lt;- solve_for_R(RF, ER_vector, CP_vector, G2, PV)\nimplied_ERP &lt;- implied_equity - RF\n\n# Number of simulations\nn_simulations &lt;- 10000\ncoeff_variation &lt;- 0.10 # Arbitrarily suggesting that COV of 10% is tight\n\n# Assumed means and standard deviations for inputs\nmean_RF &lt;- RF; sd_RF &lt;- RF * coeff_variation\nmean_ER &lt;- ER_vector; sd_ER &lt;- ER_vector * coeff_variation\nmean_CP &lt;- CP_vector; sd_CP &lt;- CP_vector * coeff_variation\nmean_G2 &lt;- G2; sd_G2 &lt;- G2 * coeff_variation\nmean_PV &lt;- PV; sd_PV &lt;- PV * coeff_variation\n\n# MC simulation\nset.seed(379)\nR_values &lt;- replicate(n_simulations, \n  solve_for_R(\n    # RF = rnorm(1, mean_RF, sd_RF),\n    RF = RF,\n    ER_vector = rnorm(6, mean_ER, sd_ER),\n    CP_vector = rnorm(6, mean_CP, sd_CP),\n    G2 = rnorm(1, mean_G2, sd_G2),\n    PV = PV\n  )\n)\n\n# Histogram to visualize the distribution of R values\nR_values &lt;- R_values[R_values &gt; 0]\nERP_values &lt;- R_values - RF\nERP_values_mean &lt;- mean(ERP_values)\nERP_values_df &lt;- as_data_frame(ERP_values)\n\nERP_values_df %&gt;% ggplot(aes(value)) +\n    geom_histogram(color = \"darkblue\", fill = \"lightblue\") +\n    geom_vline(aes(xintercept = ERP_values_mean), color = \"darkgreen\", size = 1.5) +\n    scale_x_continuous(labels = percent_format(0.01)) +\n    labs(title = \"Implied equity risk premium, ERP (n = 10,000 sims)\",\n         subtitle = \"Under tight assumption dispersion (CV = σ/μ =10%). Green vertical line is the mean.\",\n         y = \"Count\") +\n    # xlab(\"X label\") + \n    # ylab(\"Count\") +\n    theme_classic() +\n    theme(axis.title = element_blank(),\n          axis.text = element_text(size = 12, face = \"bold\"))\n\n\n\n\nQuick check on the distribution:\n\nlibrary(moments)\nskewness(ERP_values_df$value)\n\n[1] 0.08903814\n\nkurtosis(ERP_values_df$value)\n\n[1] 2.997992\n\nquantiles_v &lt;- c(0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.975, 0.99)\nquantile(ERP_values_df$value, probs = quantiles_v)\n\n        1%       2.5%         5%        10%        25%        50%        75% \n0.03041180 0.03248300 0.03433620 0.03649075 0.04004356 0.04410500 0.04832614 \n       90%        95%      97.5%        99% \n0.05209407 0.05447292 0.05638444 0.05881702 \n\n\nWhat is the relationship between the sustainable growth rate, G2, and the ERP?\n\nG2_values &lt;- seq(from = 0.02, to = 0.06, by = 0.001)\nR_values &lt;- map_dbl(G2_values, function(G2) {\n  solve_for_R(\n    RF = RF,\n    ER_vector = ER_vector,\n    CP_vector = CP_vector,\n    G2 = G2,\n    PV = PV\n  )\n})\n\nERP_values &lt;- R_values - RF\n\nG_vs_ERP &lt;-  tibble(\n  G2 = G2_values,\n  ERP = ERP_values\n)\n\nG_vs_ERP %&gt;% ggplot(aes(x = G2, y = ERP)) + \n  geom_point() + \n  coord_cartesian(ylim = c(.02, .08)) + \n  labs(title = \"Implied ERP as function of sustainable growth rate, G2\",\n       subtitle = \"Unlike prior/next visualization, predicted vectors are not randomized\")\n\n\n\n\nAnd just for fun, let’s add randomness to the earnings and cash payout vectors:\n\nG2_values &lt;- seq(from = 0.02, to = 0.06, by = 0.001)\n\nR_values &lt;- map(G2_values, function(G2) {\n  replicate(30, {\n    solve_for_R(\n      RF = RF,\n      ER_vector = rnorm(6, mean_ER, sd_ER),\n      CP_vector = rnorm(6, mean_CP, sd_CP),\n      G2 = G2,\n      PV = PV\n    ) - RF # subtracting RF here inside replicat\n  })\n})\n\ndf &lt;- tibble(\n  G2 = G2_values,\n  ERP = R_values\n) %&gt;% unnest()\n\nmodel_line &lt;- lm(ERP ~ G2, data = df)\nrsq &lt;- summary(model_line)$r.squared\nlabel_R2 &lt;- sprintf(\"R^2 = %.2f\", rsq)\n\ndf %&gt;% ggplot(aes(x = G2, y = ERP)) + \n  geom_point() +\n  coord_cartesian(ylim = c(.02, .08)) + \n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  labs(title = \"Restores 10% CV randomness to earnings and payout vectors\") +\n  annotate(\"text\", x=0.025, y=0.065, label=label_R2, fontface=\"bold\", hjust=0)\n\n\n\n  # geom_text(aes(label = label_R2))"
  },
  {
    "objectID": "posts/nearest-neighbors/index.html",
    "href": "posts/nearest-neighbors/index.html",
    "title": "Nearest neighbors",
    "section": "",
    "text": "Contents\n\nVisualizing nearest neighbors in two-dimensional feature space (simulated borrow default based on credit score and income)\nParallel coordinates plot to visualize nearest neighbors in multi-dimensional feature space (Wisconsin breast cancer dataset with 30 features)\n\nFirst the libraries:\n\nmy_libraries &lt;- c(\"tidyverse\", \"ggforce\", \"janitor\", \"openxlsx\", \"patchwork\", # for mine\n                  \"class\", \"GGally\", \"viridis\") # for Lantz's data\nlapply(my_libraries, library, character.only = TRUE)\n\nlibrary(class)\nlibrary(GGally)\nlibrary(viridis)\n\n\nPredicting loan default based on vote of nearest neighbors\nBecause it’s easy to visualize, my first example is simulated data in a two-dimensional feature space. The training set is 100 borrowers with credit scores and incomes. This is supervised learning: the borrowers either defaulted or repaid. The single test point (see blue triangle below) is a borrower with a credit score of 605 and income of $41,000.\n\nset.seed(743) \nn &lt;- 100 \n\ncredit_scores &lt;- rnorm(n, mean=650, sd=50)\nincomes &lt;- rnorm(n, mean=50000, sd=10000)\n\n# Default if credit score is below 600 OR income is below $40,000\nlabels &lt;- ifelse(credit_scores &lt; 600 | incomes &lt; 40000, \"default\", \"repay\")\n\n# But switch some \"repay\" to \"default\" to add noise\nrandom_indices &lt;- sample(1:n, n/10) # Arbitrary 10%\nlabels[random_indices] &lt;- \"default\"\n\ntrain &lt;- data.frame(credit_score=credit_scores, income=incomes, label=labels)\n# In k-nn, we should either standardize or normalize the data\nmu_credit &lt;- mean(train$credit_score); sig_credit &lt;- sd(train$credit_score)\nmu_income &lt;- mean(train$income); sig_income &lt;- sd(train$income)\ntrain$credit_score_std &lt;- (train$credit_score - mu_credit) / sig_credit\ntrain$income_std &lt;- (train$income - mu_income) / sig_income\n\n# The test point; then standardized\nx &lt;- 605\ny &lt;- 41000\nx_std &lt;- (x - mu_credit) / sig_credit\ny_std &lt;- (y - mu_income) / sig_income\n\n# Euclidean distance (from all points) to test point\ndistances_std &lt;- sqrt((train$credit_score_std - x_std)^2 + (train$income_std - y_std)^2)\n\n# The k-nearest neighbors are simply the k (=5 or =10 or =15, eg) smallest distances\nk05 &lt;- 5; k10 &lt;- 10; k15 &lt;- 15\n\nk_nearest_indices_std_05 &lt;- order(distances_std)[1:k05]\nk_nearest_indices_std_10 &lt;- order(distances_std)[1:k10]\nk_nearest_indices_std_15 &lt;- order(distances_std)[1:k15]\n\n# Add distances column and display  k-nearest neighbors with their distance\nk_nn &lt;- train[k_nearest_indices_std_15, ]\nnearest &lt;- distances_std[k_nearest_indices_std_15]\nk_nn$distance &lt;- nearest\n\n# k_nearest_neighbors\nk_nn |&gt; adorn_rounding(digits = 0, rounding = \"half up\", \n                                      all_of(c(\"credit_score\", \"income\"))) |&gt; \n    adorn_rounding(digits = 3, rounding = \"half up\", credit_score_std:distance)\n\n   credit_score income   label credit_score_std income_std distance\n8           611  41988   repay           -0.804     -0.759    0.145\n82          598  39398 default           -1.035     -1.016    0.201\n41          603  43184   repay           -0.951     -0.641    0.220\n4           592  39166 default           -1.150     -1.039    0.300\n64          604  44168   repay           -0.932     -0.543    0.315\n32          587  41994 default           -1.243     -0.759    0.345\n75          621  44367   repay           -0.618     -0.523    0.445\n53          627  38749 default           -0.513     -1.081    0.457\n1           583  46197 default           -1.307     -0.342    0.650\n45          598  34567 default           -1.045     -1.496    0.652\n11          639  43148   repay           -0.282     -0.644    0.665\n80          640  43630   repay           -0.263     -0.596    0.699\n84          643  43094   repay           -0.219     -0.650    0.723\n52          646  41064   repay           -0.156     -0.851    0.756\n99          639  45497   repay           -0.295     -0.411    0.761\n\n# Now the ggplots!\n# colors\nthree_colors &lt;- c(\"default\" = \"lightpink1\", \"repay\" = \"lightgreen\")\nfive_colors &lt;- c(\"default\" = \"lightpink1\", \"repay\" = \"lightgreen\", \"NN Default\" = \"red\", \"NN Repay\" = \"green4\")    \n\n# Base plots, with labels and without (and zoomed in per coord_cartesian)\np_base_lab &lt;- ggplot(train, aes(x=credit_score_std, y=income_std)) +\n    geom_point(aes(x=x_std, y=y_std), color=\"dodgerblue2\", shape=17, size=4) +\n    xlab(\"Credit Score (Standardized)\") +\n    ylab(\"Income (Standardized)\") +\n    theme_minimal()\n\np_base &lt;- ggplot(train, aes(x=credit_score_std, y=income_std)) + \n    geom_point(aes(x=x_std, y=y_std), color=\"dodgerblue2\", shape=17, size=4) +\n    theme_minimal() +\n    theme(legend.position = \"none\", axis.title = element_blank()) +\n    coord_cartesian(xlim = c(-1.75, 0), ylim = c(-1.75, 0))\n\np1_lab &lt;- p_base_lab + \n    geom_point(aes(color = label), size = 3) + \n    labs(title = paste(\"The majority of how many k neighbors?\"),\n         subtitle = paste(\"Blue triangle is Test point\"),\n         color = \"Borrower\") +\n    scale_color_manual(values = three_colors)\n\np3_lab &lt;- p_base_lab +\n    geom_point(aes(color = ifelse(row.names(train) %in% row.names(train[k_nearest_indices_std_10, ]),\n                                  ifelse(label == \"default\", \"NN Default\", \"NN Repay\"),\n                                  label)), size = 3) +\n    labs(title = paste(\"Let's ask k = 10 neighbors to vote\"),\n         subtitle = paste(\"Six defaulted and four repaid (radius is ~0.652)\"),\n         color = \"Borrower\") +\n    geom_circle(aes(x0 = x_std, y0 = y_std, r = 0.658), \n              color = \"blue\",linetype=\"dashed\", fill = NA) +\n    scale_color_manual(values = five_colors)\n\np1_lab\n\n\n\np3_lab\n\n\n\np1 &lt;- p_base + \n    geom_point(aes(color = label), size = 3) +\n    scale_color_manual(values = three_colors)\n\np2 &lt;- p_base + \n    geom_point(aes(color = ifelse(row.names(train) %in% row.names(train[k_nearest_indices_std_05, ]),\n                                  ifelse(label == \"default\", \"NN Default\", \"NN Repay\"),\n                                  label)), size = 3) +\n    geom_circle(aes(x0 = x_std, y0 = y_std, r = 0.330), \n              color = \"blue\",linetype=\"dashed\", fill = NA) +\n    scale_color_manual(values = five_colors) \n\n p3 &lt;- p_base +\n    geom_point(aes(color = ifelse(row.names(train) %in% row.names(train[k_nearest_indices_std_10, ]),\n                                  ifelse(label == \"default\", \"NN Default\", \"NN Repay\"),\n                                  label)), size = 3) +\n    geom_circle(aes(x0 = x_std, y0 = y_std, r = 0.658), \n              color = \"blue\",linetype=\"dashed\", fill = NA) +\n    scale_color_manual(values = five_colors)\n\n p4 &lt;- p_base +\n    geom_point(aes(color = ifelse(row.names(train) %in% row.names(train[k_nearest_indices_std_15, ]),\n                                  ifelse(label == \"default\", \"NN Default\", \"NN Repay\"),\n                                  label)), size = 3) +\n     geom_circle(aes(x0 = x_std, y0 = y_std, r = 0.763), \n              color = \"blue\",linetype=\"dashed\", fill = NA) +\n    scale_color_manual(values = five_colors) \n\n(p1 | p2) / (p3 | p4) + \n     plot_annotation(title = \"Top: None and k = 5, Bottom: k = 10 and k = 15\", \n                     subtitle = \"From repay (3/5) to default (6/10) to repay (9/15)\")\n\n\n\n\n\n\nPredicting default based on vote of nearest neighbors\nMost datasets have many features. I quickly tried a few experiments to visualize multidimensional neighbors. At this point, my favorite is the parallel coordinates plot below. I’ll use the dataset from my favorite machine learning introduction: Machine Learning with R by Brent Lantz, 4th Edition. He did not attempt to visualize this nearest neighbor’s example.\nWe’re using the Wisconsin Breast Cancer Dataset. The dataset has 569 observations and 30 numeric features that describe characteristics of the cell nuclei present in the image. The target variable is the diagnosis (benign or malignant).\nBrett Lantz parses the dataset into 469 training observation and 100 test observations. Please note that these features are normalized (i.e., on a zero to one scale) rather than standardized (as I did above). Below, I retrieve the first test instance and plot its two nearest (Euclidean) neighbors in the training set. Although this does not convey numerical distance (obviously), I think it’s a fine way to illustrate the proximity of the features.\n\nload(\"wbcd_dfs.RData\") # wbcd_train, wbcd_train_labels, wbcd_test, wbcd_test_labels\n# I previously retrieved the nearest neighbors to the single test instance\n# k_nearest neighbors &lt;- function(test_instance, train_data, k)\n# save(k_neighbors, file = \"k_neighbors.RData\")\nload(\"k_neighbors.RData\") # k_neighbors\n\nstr(wbcd_train)\n\n'data.frame':   469 obs. of  30 variables:\n $ radius_mean      : num  0.253 0.171 0.192 0.203 0.389 ...\n $ texture_mean     : num  0.0906 0.3125 0.2408 0.1245 0.1184 ...\n $ perimeter_mean   : num  0.242 0.176 0.187 0.202 0.372 ...\n $ area_mean        : num  0.136 0.0861 0.0974 0.1024 0.2411 ...\n $ smoothness_mean  : num  0.453 0.399 0.497 0.576 0.244 ...\n $ compactness_mean : num  0.155 0.292 0.18 0.289 0.153 ...\n $ concavity_mean   : num  0.0934 0.1496 0.0714 0.1086 0.0795 ...\n $ points_mean      : num  0.184 0.131 0.123 0.238 0.132 ...\n $ symmetry_mean    : num  0.454 0.435 0.33 0.359 0.334 ...\n $ dimension_mean   : num  0.202 0.315 0.283 0.227 0.115 ...\n $ radius_se        : num  0.0451 0.1228 0.0309 0.0822 0.0242 ...\n $ texture_se       : num  0.0675 0.1849 0.2269 0.2172 0.0116 ...\n $ perimeter_se     : num  0.043 0.1259 0.0276 0.0515 0.0274 ...\n $ area_se          : num  0.0199 0.0379 0.0126 0.0365 0.0204 ...\n $ smoothness_se    : num  0.215 0.196 0.117 0.325 0.112 ...\n $ compactness_se   : num  0.0717 0.252 0.0533 0.2458 0.0946 ...\n $ concavity_se     : num  0.0425 0.0847 0.0267 0.0552 0.0392 ...\n $ points_se        : num  0.235 0.259 0.142 0.372 0.173 ...\n $ symmetry_se      : num  0.16 0.382 0.131 0.111 0.121 ...\n $ dimension_se     : num  0.0468 0.0837 0.045 0.088 0.0301 ...\n $ radius_worst     : num  0.198 0.141 0.159 0.142 0.294 ...\n $ texture_worst    : num  0.0965 0.291 0.3843 0.0999 0.0989 ...\n $ perimeter_worst  : num  0.182 0.139 0.147 0.13 0.269 ...\n $ area_worst       : num  0.0894 0.0589 0.0703 0.0611 0.1558 ...\n $ smoothness_worst : num  0.445 0.331 0.434 0.433 0.274 ...\n $ compactness_worst: num  0.0964 0.2175 0.1173 0.1503 0.142 ...\n $ concavity_worst  : num  0.0992 0.153 0.0852 0.0692 0.1088 ...\n $ points_worst     : num  0.323 0.272 0.255 0.296 0.281 ...\n $ symmetry_worst   : num  0.249 0.271 0.282 0.106 0.182 ...\n $ dimension_worst  : num  0.0831 0.1366 0.1559 0.084 0.0828 ...\n\n# this knn() function is from the class package\n# and it classifies the test set; e.g., 1st is classified as Benign\nwbcd_test_pred &lt;- knn(train = wbcd_train, test = wbcd_test,\n                      cl = wbcd_train_labels, k = 21)\nwbcd_test_pred[1]\n\n[1] Benign\nLevels: Benign Malignant\n\n# inserting first instance at top of training set for graph\nwbcd_train &lt;- rbind(wbcd_test[1, ], wbcd_train) # 469 + 1 = 470\n\nwbcd_train$group &lt;- \"Others\"\nwbcd_train$group[1] &lt;- \"Test Instance\"\nobs_2_index &lt;- k_neighbors[1] + 1\nwbcd_train$group[obs_2_index] &lt;- \"Nearest #1\"\nobs_3_index &lt;- k_neighbors[2] + 1\nwbcd_train$group[obs_3_index] &lt;- \"Nearest #2\"\n\n# set.seed(479)\nset.seed(48514)\n\n# Set the row indices you want to include\nrow1 &lt;- 1\nrow2 &lt;- obs_2_index\nrow3 &lt;- obs_3_index\n\n# Number of random rows to sample\nn &lt;- 10\n\n# Sample without the specific rows, then combine with the specific rows\nsampled_indices &lt;- sample(setdiff(1:nrow(wbcd_train), c(row1, row2, row3)), n)\nfinal_sample &lt;- rbind(wbcd_train[c(row1, row2, row3), ], wbcd_train[sampled_indices, ])\n\nfinal_sample |&gt; ggparcoord(columns = 1:30, \n                           groupColumn = \"group\",\n                           showPoints = TRUE,\n                           alphaLines = 0.3,\n                           scale = \"uniminmax\") +\n    scale_color_manual(values = c(\"Test Instance\" = \"blue\",\n                                  \"Nearest #1\" = \"green4\",\n                                  \"Nearest #2\" = \"green4\",\n                                  \"Others\" = \"yellow\")) + \n    theme_minimal() +\n    labs(title = \"Parallel Coordinates Plot\") +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n    coord_flip()"
  },
  {
    "objectID": "posts/decision-tree-p1/index.html",
    "href": "posts/decision-tree-p1/index.html",
    "title": "Decision Trees (part 1)",
    "section": "",
    "text": "Contents\n\nTrain (and graph) dividend payer with rpart(), rpart.plot and C5.0\nLoan default train\nLoan default prediction\nAdding penalty matrix to make false negatives costly\nTrees are random but not too fragile\n\nTo write a PQ set for decision trees, I experimented below. First the libraries:\n\nmy_libraries &lt;- c(\"C50\", \"gmodels\", \"tidyverse\", \"openxlsx\", \n                  \"rattle\", \"rpart\", \"rpart.plot\")\nlapply(my_libraries, library, character.only = TRUE)\n\n\nPredicting dividend\nGARP’s motivating example is a super simple (n = 20) dataset of public companies the either pay or do not pay a Dividend. The my20firms dataframe (you can see) is slightly altered to achieve a tree that I liked better for purposes of a practice question:\n\n# my20firms &lt;- garp_data\n# my20firms$Dividend[1] &lt;- 0\n# my20firms$Dividend[9] &lt;- 0\n# my20firms$Dividend[12] &lt;- 1\n# my20firms$Dividend[13] &lt;- 0\n# my20firms$Dividend[15] &lt;- 0\n\n# colnames(my20firms)[colnames(my20firms) == \"Retail_investor\"] &lt;- \"Retail\"\n# colnames(my20firms)[colnames(my20firms) == \"Large_cap\"] &lt;- \"LargeCap\"\n\n# write.xlsx(my20firms, file = \"dividendExampleModified_v3.xlsx\")\n# my20firms &lt;- read.xlsx(\"dividendExampleModified_v3.xlsx\")\n# saveRDS(my20firms, file = \"my20firms-rds.RDS\")\n\nmy20firms &lt;- readRDS(\"my20firms-rds.RDS\")\nmy20firms\n\n   Dividend Earnings LargeCap Retail Tech\n1         0        0        1     40    1\n2         1        1        1     30    0\n3         1        1        1     20    0\n4         0        0        0     80    1\n5         1        0        1     20    0\n6         0        1        0     30    1\n7         0        1        0     40    0\n8         1        0        1     60    0\n9         0        1        1     20    1\n10        0        1        1     40    0\n11        0        0        0     20    1\n12        1        0        1     70    0\n13        0        1        0     30    1\n14        1        0        1     70    0\n15        0        0        1     50    1\n16        1        0        1     60    1\n17        1        1        1     30    0\n18        0        1        0     30    1\n19        0        0        0     40    0\n20        1        1        1     50    0\n\nfit2 &lt;- rpart(Dividend ~ ., data = my20firms, \n              parms = list(split = \"gini\"),\n              control = rpart.control(minsplit = 1, \n                                      minbucket = 1,\n                                      maxdepth = 4))\n\n# summary(fit2) printout is too long\nprint(fit2)\n\nn= 20 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 20 4.9500000 0.4500000  \n   2) LargeCap&lt; 0.5 7 0.0000000 0.0000000 *\n   3) LargeCap&gt;=0.5 13 2.7692310 0.6923077  \n     6) Tech&gt;=0.5 4 0.7500000 0.2500000  \n      12) Retail&lt; 55 3 0.0000000 0.0000000 *\n      13) Retail&gt;=55 1 0.0000000 1.0000000 *\n     7) Tech&lt; 0.5 9 0.8888889 0.8888889  \n      14) Earnings&gt;=0.5 5 0.8000000 0.8000000  \n        28) Retail&gt;=35 2 0.5000000 0.5000000 *\n        29) Retail&lt; 35 3 0.0000000 1.0000000 *\n      15) Earnings&lt; 0.5 4 0.0000000 1.0000000 *\n\nprintcp(fit2)\n\n\nRegression tree:\nrpart(formula = Dividend ~ ., data = my20firms, parms = list(split = \"gini\"), \n    control = rpart.control(minsplit = 1, minbucket = 1, maxdepth = 4))\n\nVariables actually used in tree construction:\n[1] Earnings LargeCap Retail   Tech    \n\nRoot node error: 4.95/20 = 0.2475\n\nn= 20 \n\n        CP nsplit rel error  xerror     xstd\n1 0.440559      0   1.00000 1.11610 0.056479\n2 0.228352      1   0.55944 1.12013 0.298518\n3 0.151515      2   0.33109 1.04063 0.309021\n4 0.039282      3   0.17957 0.81948 0.360160\n5 0.010000      5   0.10101 0.80808 0.361385\n\nrpart.plot(fit2, yesno = 2, left=FALSE, type=2, branch.lty = 3, nn= TRUE, \n           box.palette = \"BuGn\", leaf.round=0)\n\n\n\n# converting the target to factor\nmy20firms$Dividend &lt;- as_factor(my20firms$Dividend)\n\n\nfit3 &lt;- rpart(Dividend ~ ., data = my20firms, \n              parms = list(split = \"gini\"),\n              control = rpart.control(minsplit = 1, \n                                      minbucket = 1,\n                                      maxdepth = 4))\n\nprint(fit3)\n\nn= 20 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 20 9 0 (0.5500000 0.4500000)  \n   2) LargeCap&lt; 0.5 7 0 0 (1.0000000 0.0000000) *\n   3) LargeCap&gt;=0.5 13 4 1 (0.3076923 0.6923077)  \n     6) Tech&gt;=0.5 4 1 0 (0.7500000 0.2500000)  \n      12) Retail&lt; 55 3 0 0 (1.0000000 0.0000000) *\n      13) Retail&gt;=55 1 0 1 (0.0000000 1.0000000) *\n     7) Tech&lt; 0.5 9 1 1 (0.1111111 0.8888889) *\n\nrpart.plot(fit3, yesno = 2, left=FALSE, type=2, branch.lty = 3, nn= TRUE, \n           box.palette = \"BuGn\", leaf.round=0)\n\n\n\n\nI had to refresh my knowledge of decision trees, and for that I depended on the awesome book () that I will review in the future (almost done!). He uses C5.0 algorithm (per the C50 package) and I just wanted to see its defaults:\n\ntree_c5 &lt;- C5.0(Dividend ~ ., data = my20firms)\nplot(tree_c5)\n\n\n\n# set MinCases = 1\n\ntree_c5_v2 &lt;- C5.0(Dividend ~ ., \n                   control = C5.0Control(minCases = 1),\n                   data = my20firms)\nplot(tree_c5_v2)\n\n\n\n\n\n\nLoan default examples\nNow I will switch datasets, and use the same loan default dataset used in the book. But I will use the more familiar rpart() function to train the tree. The result is similar but not identical (and please not the difference is not due to sampling varation: my test sample is the same).\n\nset.seed(9829)\ntrain_sample &lt;- sample(1000, 900)\n\ncredit &lt;- read.csv(\"credit.csv\", stringsAsFactors = TRUE)\n\n# split the data frames\ncredit_train &lt;- credit[train_sample, ]\ncredit_test  &lt;- credit[-train_sample, ]\n\ncredit_train$credit_history &lt;- credit_train$credit_history |&gt; \n    fct_relevel(\"critical\", \"poor\", \"good\", \"very good\", \"perfect\")\n\ntree_credit_train &lt;- rpart(default ~ ., data = credit_train,\n                           parms = list(split = \"gini\"),\n                           control = rpart.control(minsplit = 1, \n                                                   minbucket = 1,\n                                                   maxdepth = 4))\n\nrpart.plot(tree_credit_train, yesno = 2, left=FALSE, type=2, branch.lty = 3, nn= TRUE, \n           box.palette = c(\"palegreen\", \"pink\"), leaf.round=0, extra = 101, digits = 4)\n\n\n\nprint(tree_credit_train)\n\nn= 900 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 900 265 no (0.7055556 0.2944444)  \n   2) checking_balance=&gt; 200 DM,unknown 415  55 no (0.8674699 0.1325301) *\n   3) checking_balance=&lt; 0 DM,1 - 200 DM 485 210 no (0.5670103 0.4329897)  \n     6) credit_history=critical,poor,good 426 167 no (0.6079812 0.3920188)  \n      12) months_loan_duration&lt; 27.5 324 105 no (0.6759259 0.3240741)  \n        24) amount&lt; 9899.5 317  98 no (0.6908517 0.3091483) *\n        25) amount&gt;=9899.5 7   0 yes (0.0000000 1.0000000) *\n      13) months_loan_duration&gt;=27.5 102  40 yes (0.3921569 0.6078431)  \n        26) dependents&gt;=1.5 14   4 no (0.7142857 0.2857143) *\n        27) dependents&lt; 1.5 88  30 yes (0.3409091 0.6590909) *\n     7) credit_history=very good,perfect 59  16 yes (0.2711864 0.7288136)  \n      14) age&lt; 22.5 3   0 no (1.0000000 0.0000000) *\n      15) age&gt;=22.5 56  13 yes (0.2321429 0.7678571) *\n\nprintcp(tree_credit_train)\n\n\nClassification tree:\nrpart(formula = default ~ ., data = credit_train, parms = list(split = \"gini\"), \n    control = rpart.control(minsplit = 1, minbucket = 1, maxdepth = 4))\n\nVariables actually used in tree construction:\n[1] age                  amount               checking_balance    \n[4] credit_history       dependents           months_loan_duration\n\nRoot node error: 265/900 = 0.29444\n\nn= 900 \n\n        CP nsplit rel error  xerror     xstd\n1 0.050943      0   1.00000 1.00000 0.051599\n2 0.026415      3   0.81509 0.83396 0.048726\n3 0.022642      4   0.78868 0.82642 0.048577\n4 0.011321      5   0.76604 0.81887 0.048425\n5 0.010000      6   0.75472 0.81887 0.048425\n\n\n\n\nDefault prediction\nBecause there is a 10% test set, we can test the decision tree. It’s not great. In terms of the mistake, notice that 28/35 actual defaulters were incorrectly predicted to repay; that’s terrible. Compare this to only 7/65 actual re-payers who were predicted to default.\n\ntree_credit_pred &lt;- predict(tree_credit_train, credit_test, type = \"class\")\n\n\nCrossTable(credit_test$default, tree_credit_pred,\n           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,\n           dnn = c('actual default', 'predicted default'))\n\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  100 \n\n \n               | predicted default \nactual default |        no |       yes | Row Total | \n---------------|-----------|-----------|-----------|\n            no |        58 |         7 |        65 | \n               |     0.580 |     0.070 |           | \n---------------|-----------|-----------|-----------|\n           yes |        28 |         7 |        35 | \n               |     0.280 |     0.070 |           | \n---------------|-----------|-----------|-----------|\n  Column Total |        86 |        14 |       100 | \n---------------|-----------|-----------|-----------|\n\n \n\n\n\n\nAdding a loss (aka, penalty, cost) matrix\nIt’s really easy to impose a penalty matrix. We will make the false negative three times more costly than a false positive. As desired, the false negatives flip with huge improvement: the updated model correctly traps 28/35 defaults with only 7/35 false negatives. But this comes with an equally huge trade-off: false positives jump from 7/65 to 27 out of 65 who are predicted to default but actually repay.\n\npenalty_matrix &lt;- matrix(c(0, 3,   # Actual: No\n                           1, 0),  # Actual: Yes\n                         ncol=2)\n\nrownames(penalty_matrix) &lt;- colnames(penalty_matrix) &lt;- c(\"No\", \"Yes\")\n\ntree_credit_cost_train &lt;- rpart(default ~ ., data = credit_train,\n                           parms = list(split = \"gini\", loss=penalty_matrix),\n                           control = rpart.control(minsplit = 1, \n                                                   minbucket = 1,\n                                                   maxdepth = 4))\n\ntree_credit_cost_pred &lt;- predict(tree_credit_cost_train, credit_test, type = \"class\")\n\nCrossTable(credit_test$default, tree_credit_cost_pred,\n           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,\n           dnn = c('actual default', 'predicted default'))\n\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  100 \n\n \n               | predicted default \nactual default |        no |       yes | Row Total | \n---------------|-----------|-----------|-----------|\n            no |        38 |        27 |        65 | \n               |     0.380 |     0.270 |           | \n---------------|-----------|-----------|-----------|\n           yes |         7 |        28 |        35 | \n               |     0.070 |     0.280 |           | \n---------------|-----------|-----------|-----------|\n  Column Total |        45 |        55 |       100 | \n---------------|-----------|-----------|-----------|\n\n \n\n\n\n\nCan I easily randomize?\nI’m interested in the fact that decision trees have random qualities (aside from sampling variation). Below I set a different seed and switched the split algo to entropy. But the ultimate tree is the same.\n\n# different see and switch gini to information; aka, entropy\nset.seed(448)\n\ntree_credit_train_2 &lt;- rpart(default ~ ., data = credit_train,\n                           parms = list(split = \"information\"),\n                           control = rpart.control(minsplit = 1, \n                                                   minbucket = 1,\n                                                   maxdepth = 4))\n\nrpart.plot(tree_credit_train_2, yesno = 2, left=FALSE, type=2, branch.lty = 3, nn= TRUE, \n           box.palette = c(\"palegreen\", \"pink\"), leaf.round=0, extra = 101, digits = 4)\n\n\n\nprint(tree_credit_train_2)\n\nn= 900 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 900 265 no (0.7055556 0.2944444)  \n   2) checking_balance=&gt; 200 DM,unknown 415  55 no (0.8674699 0.1325301) *\n   3) checking_balance=&lt; 0 DM,1 - 200 DM 485 210 no (0.5670103 0.4329897)  \n     6) credit_history=critical,poor,good 426 167 no (0.6079812 0.3920188)  \n      12) months_loan_duration&lt; 27.5 324 105 no (0.6759259 0.3240741)  \n        24) amount&lt; 9899.5 317  98 no (0.6908517 0.3091483) *\n        25) amount&gt;=9899.5 7   0 yes (0.0000000 1.0000000) *\n      13) months_loan_duration&gt;=27.5 102  40 yes (0.3921569 0.6078431)  \n        26) dependents&gt;=1.5 14   4 no (0.7142857 0.2857143) *\n        27) dependents&lt; 1.5 88  30 yes (0.3409091 0.6590909) *\n     7) credit_history=very good,perfect 59  16 yes (0.2711864 0.7288136)  \n      14) age&lt; 22.5 3   0 no (1.0000000 0.0000000) *\n      15) age&gt;=22.5 56  13 yes (0.2321429 0.7678571) *\n\nprintcp(tree_credit_train_2)\n\n\nClassification tree:\nrpart(formula = default ~ ., data = credit_train, parms = list(split = \"information\"), \n    control = rpart.control(minsplit = 1, minbucket = 1, maxdepth = 4))\n\nVariables actually used in tree construction:\n[1] age                  amount               checking_balance    \n[4] credit_history       dependents           months_loan_duration\n\nRoot node error: 265/900 = 0.29444\n\nn= 900 \n\n        CP nsplit rel error  xerror     xstd\n1 0.050943      0   1.00000 1.00000 0.051599\n2 0.026415      3   0.81509 0.87547 0.049518\n3 0.022642      4   0.78868 0.86038 0.049236\n4 0.011321      5   0.76604 0.86415 0.049307\n5 0.010000      6   0.75472 0.86038 0.049236\n\nidentical(tree_credit_train, tree_credit_train_2)\n\n[1] FALSE\n\nall.equal(tree_credit_train, tree_credit_train_2)\n\n[1] \"Component \\\"call\\\": target, current do not match when deparsed\"                                \n[2] \"Component \\\"cptable\\\": Mean relative difference: 0.04736418\"                                   \n[3] \"Component \\\"parms\\\": Component \\\"split\\\": Mean relative difference: 1\"                         \n[4] \"Component \\\"splits\\\": Attributes: &lt; Component \\\"dimnames\\\": Component 1: 4 string mismatches &gt;\"\n[5] \"Component \\\"splits\\\": Mean relative difference: 5.545437\"                                      \n[6] \"Component \\\"csplit\\\": Attributes: &lt; Component \\\"dim\\\": Mean relative difference: 0.04761905 &gt;\" \n[7] \"Component \\\"csplit\\\": Numeric: lengths (126, 120) differ\"                                      \n[8] \"Component \\\"variable.importance\\\": Names: 2 string mismatches\"                                 \n[9] \"Component \\\"variable.importance\\\": Mean relative difference: 0.1894674\""
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About David",
    "section": "",
    "text": "Hello! I’m David Harper, CFA, FRM. I started bionicturtle.com in 2004 and built it into the #1 exam preparation provider (EPP) for the Financial Risk Manager (FRM). In February of 2021, I sold the business to CeriFi where I continue to run it as President, Bionic Turtle, a CeriFi company. And now I’m part of a great team that is building the world’s greatest platform for financial education at every stage of your career.\nI love learning about (and teaching) risk. I also write investing articles at Seeking Alpha, where I disclose my portfolio/trades and practice risk management. My focus is disruptive technologies, patient GARP-style with a portfolio risk overlay; e.g., diversification. The market wants growth but I’m a value technician at heart, consequently I am willing to wait for great companies to prove their worth to the general audience. I have a BA, Economics from UC, Berkeley. I earned my CFA in 2003 and my FRM in 2004.\nI’ve been training and practicing data science for several years. Of course, my preferred data tool is R (aka, #RStats, #rstat). The best thing about R is the amazing community, there is nothing quite like an RStudio conference. Online I try to keep sharp with Coursera, datacamp and perhaps the most talented data science instructor on the planet: Matt Dancho’s Business Science.\nI am extremely interested (and invested) in digital disruption and the future of work (FOW), including EdTech, talent marketplaces and work management (my favorite software is wrike).\nThis is a Quarto site using the built-in sandstone theme"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FinEdTech by DH",
    "section": "",
    "text": "Univariate regression\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nDescription to go here\n\n\n\n\n\n\nOct 22, 2023\n\n\nDavid Harper, CFA, FRM\n\n\n\n\n\n\n  \n\n\n\n\nNearest neighbors\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nThis lazy learning algorithm requires us to select k, but it’s a fast and intuitive classifer\n\n\n\n\n\n\nOct 13, 2023\n\n\nDavid Harper, CFA, FRM\n\n\n\n\n\n\n  \n\n\n\n\nDecision Trees (part 1)\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nJust some description here for now\n\n\n\n\n\n\nOct 7, 2023\n\n\nDavid Harper, CFA, FRM\n\n\n\n\n\n\n  \n\n\n\n\nThis is a Quarto website\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nPosit’s brilliant system executes either R or python code (and a GPT API example)\n\n\n\n\n\n\nSep 15, 2023\n\n\nDavid Harper\n\n\n\n\n\n\n  \n\n\n\n\nLogistic regression coefficients\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nFitting a logistic regression model is easy in R, but coefficient interpretation is non-trivial\n\n\n\n\n\n\nSep 4, 2023\n\n\nDavid Harper, CFA, FRM\n\n\n\n\n\n\n  \n\n\n\n\nSimulating the equity risk premium\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nThe implied ERP is very sensitive to assumptions, in particular G2\n\n\n\n\n\n\nAug 31, 2023\n\n\nDavid Harper, CFA, FRM\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To FinEdTech\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 30, 2023\n\n\nDavid Harper\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/logistic-coeff/index.html",
    "href": "posts/logistic-coeff/index.html",
    "title": "Logistic regression coefficients",
    "section": "",
    "text": "I wanted to shadow GARP’s logistic regression example, so I sampled from the same LendingClub database and performed a similar logistic regression. The key difference is practical: I’ll often re-sample from the data in order to get a result that lends itself to a good practice question. I’ve been writing practice questions for a long time, and there are many little details that go into this. For example, GARP’s logistic regression shows 10 independent variables, and I reduced that to seven merely because I don’t need to show all the variables to make the point.\nAfter I seeded the result that appealed to me, I wrote the practice question below (the published question sans answer is here). After fiddling with the four choices, I’m happy with the final question. It’s an “EXCEPT FOR” question, which is what I often use when I’m trying to blanked the concept more comprehensively than a “TRUE” question. This is a bit more work because each distractor must be carefully written.\n\n23.6.1. Darlene is a risk analyst who evaluate the creditworthiness of loan applicants at her financial institution. Her department is testing a new logistic regression model. If the model performs well in testing, it will be deployed to assist in the underwriting decision-making process. The training data is a sub-sample (n = 800) from the same LendingClub database used in reading. In the logistic regression, the dependent variable is a 0/1 for the terminal state of the loan being either zero (fully paid off) or one (deemed irrecoverable or defaulted). In the actual code, this dependent variable is labeled ‘outcome’.\nThe following are the features (aka, independent variables) as given by their textual labels: Amount, Term, Interest_rate, Installment, Employ_hist, Income, and Bankruptcies. In regard to units in the database, please note the following: Amount is thousands of dollars ($000s); Term is months; Interest_rate is effectively multiplied by one hundred such that 7 equates to 7% or 0.070; Installment is dollars; Employment_hist is years; Income is thousand of dollars ($000); and Bankruptcies is a whole number {0, 1, 2, …}.\nThe table below displays the logistic regression results:\n&lt;&lt;See regression output below; table will paste here&gt;&gt;\n\n\nIn regard to this logistic regression, each of the following statements is true EXCEPT which is false?\n\nA single additional bankruptcy increases the expected odds of default by almost 58 percent\nIf she requires significance at the 5% level or better, then two of the coefficients (in addition to the intercept) are significant\nEach +100 basis points increase in the interest rate (e.g., from 8.0% to 9.0%) implies an increase of about 14.0 basis points in the default probability\nIf the cost of making a bad loan is high, she can decrease the threshold (i.e., set Z to a low value such as 0.05), but this will reject more good borrowers\n\n\nHere is the code with some comments. The logistic model itself, a type of glm(), requires only a single line and the model is stored in logit_model_1 as a list object. Most of my code is re-coding the dataset, and then rendering the model’s coefficients with the awesome gt package. Posit’s Richard Iannone does an incredible job maintaining the package. If you think about it, generating tables are really important in data!\n\nlibrary(tidyverse) \nlibrary(gt)\n# library(labelled) Didn't use but helpful\n\n# set.seed(xzy)\nset.seed(374)\n\nsample_size &lt;- 800\nlcfeatures &lt;- read_csv(\"lcfeatures.csv\") \n# Same LendingClub dataset used in FRM Chapter 15 (Logistic Regression Example)\n# Located at https://www.kaggle.com/datasets/wordsforthewise/lending-club\n# But lcfeatures is a random sample of 10,000 which is too large for my need\n# So I just sample_n as random subset of the 10,000\nlcfeatures &lt;- lcfeatures |&gt; sample_n(sample_size)\n\n# recoding \nlcfeatures$emp_length_n &lt;- gsub(\"&lt; 1\", \"0\", lcfeatures$emp_length)\nlcfeatures$emp_length_n2 &lt;- parse_number(lcfeatures$emp_length_n)\nlcfeatures$term_n &lt;- parse_number(lcfeatures$term)\n\nlcfeatures$home_ownership_simpler &lt;- recode(lcfeatures$home_ownership,\n                                             \"MORTGAGE\" = \"OWN\",\n                                             \"ANY\" = \"RENT\",\n                                             \"NONE\" = \"RENT\")\n\nlcfeatures$mortgage_simpler &lt;- recode(lcfeatures$home_ownership,\n                                       \"OWN\" = \"NO\",\n                                       \"ANY\" = \"NO\",\n                                       \"NONE\" = \"NO\",\n                                       \"RENT\" = \"NO\",\n                                       \"MORTGAGE\" = \"YES\")\n\nlcfeatures$loan_status_coded &lt;- recode(lcfeatures$loan_status,\n                                        \"Charged Off\" = \"Default\",\n                                        \"Does not meet the credit policy. Status:Charged Off\" = \"Default\",\n                                        \"Late (31-120 days)\" = \"Default\",\n                                        .default = \"Paid\")\n\nlcfeatures$home_ownership_bern &lt;- recode(lcfeatures$home_ownership_simpler,\n                                          \"RENT\" = 0,\n                                          \"OWN\" = 1)\n\nlcfeatures$mortgage_bern &lt;- recode(lcfeatures$mortgage_simpler,\n                                          \"NO\" = 0,\n                                          \"YES\" = 1)\n\nlcfeatures$loan_status_bern &lt;- recode(lcfeatures$loan_status_coded,\n                                          \"Paid\" = 0,\n                                          \"Default\" = 1)\n\nlcfeatures$loan_amnt_000 &lt;- lcfeatures$loan_amnt / 1000\nlcfeatures$annual_inc_000 &lt;- lcfeatures$annual_inc / 1000\nlcfeatures$outcome &lt;- lcfeatures$loan_status_bern\n\n# This is logistic regression model\nlogit_model_1 &lt;- glm(formula = outcome ~ loan_amnt_000 + term_n + int_rate + installment + \n        emp_length_n2 + annual_inc_000 + pub_rec_bankruptcies,\n        family = binomial(link = \"logit\"), data = lcfeatures)\n\ncoef_table &lt;- coef(summary(logit_model_1)) \ncoef_tbl  &lt;-  as_tibble(coef_table)\nCoeff_labels &lt;- c(\"(Intercept)\", \"Amount\", \"Term\", \"Interest_rate\", \"Installment\", \n                 \"Employment_hist\", \"Income\",\"Bankruptcies\")\ncoef_tbl &lt;- cbind(Coeff_labels, coef_tbl)\n\n# Using gt() to render a table\ncoef_tbl_gt &lt;- coef_tbl %&gt;% gt() |&gt; \n    opt_table_font(stack = \"humanist\") |&gt;\n    fmt_number(columns = everything(),\n               decimals = 3)\ncoef_tbl_gt\n\n\n\n\n\n  \n    \n    \n      Coeff_labels\n      Estimate\n      Std. Error\n      z value\n      Pr(&gt;|z|)\n    \n  \n  \n    (Intercept)\n−2.329\n0.841\n−2.769\n0.006\n    Amount\n0.123\n0.092\n1.339\n0.181\n    Term\n−0.041\n0.027\n−1.519\n0.129\n    Interest_rate\n0.140\n0.034\n4.108\n0.000\n    Installment\n−0.003\n0.003\n−1.033\n0.302\n    Employment_hist\n−0.032\n0.031\n−1.025\n0.305\n    Income\n−0.003\n0.003\n−0.937\n0.349\n    Bankruptcies\n0.457\n0.230\n1.991\n0.046\n  \n  \n  \n\n\n\n\nIf we use predict() with type = “response”, then the logistic regression returns the vector of predicted probabilities (from zero to 100%). We can classify the Bernoulli prediction (0 = nondefault, 1 = default) as a function of our desired conservative/aggressive threshold. Below I show the number of rejections would increase as we lower the threshold.\n\npredicted_probs &lt;- predict(logit_model_1, lcfeatures, type = \"response\")\nthresholds &lt;- c(0.4, 0.3, 0.2, 0.1, 0.05, 0.010)\nthresholds |&gt; map_int(\\(x) sum(ifelse(predicted_probs &gt; x, 1, 0), na.rm = TRUE))\n\n[1]   5  30  86 383 689 748\n\n\nInspired by this blog post on color coding the {gt} table, I added some color to highlight the significant coefficients (obviously not in the actual Q&A, just here!):\n\ncoef_tbl_gt |&gt; \n    data_color(\n        columns = 'Pr(&gt;|z|)', \n        palette = c(\"#19F000\",\"#E4FF00\"),\n        domain = c(0,0.05),\n        na_color = \"lightgrey\"\n    )\n\n\n\n\n\n  \n    \n    \n      Coeff_labels\n      Estimate\n      Std. Error\n      z value\n      Pr(&gt;|z|)\n    \n  \n  \n    (Intercept)\n−2.329\n0.841\n−2.769\n0.006\n    Amount\n0.123\n0.092\n1.339\n0.181\n    Term\n−0.041\n0.027\n−1.519\n0.129\n    Interest_rate\n0.140\n0.034\n4.108\n0.000\n    Installment\n−0.003\n0.003\n−1.033\n0.302\n    Employment_hist\n−0.032\n0.031\n−1.025\n0.305\n    Income\n−0.003\n0.003\n−0.937\n0.349\n    Bankruptcies\n0.457\n0.230\n1.991\n0.046"
  },
  {
    "objectID": "posts/regression-simple/index.html",
    "href": "posts/regression-simple/index.html",
    "title": "Univariate regression",
    "section": "",
    "text": "Illustration of residual sum of squares (RSS) with n = 12 subset\nUnivariate (aka, simple) linear regression: AAPL vs S&P 1500, n = 72 months\nModel diagnostics\nAutocorrelation test\n\nLoading packages\n\nlibrary(tidyverse); library(gt)\nlibrary(patchwork)\n\nlibrary(broom); library(performance); library(lmtest)\nlibrary(desk)"
  },
  {
    "objectID": "posts/regression-simple/index.html#regressing-apples-aapl-returns-against-sp-1500",
    "href": "posts/regression-simple/index.html#regressing-apples-aapl-returns-against-sp-1500",
    "title": "Univariate regression",
    "section": "Regressing Apple’s (AAPL) returns against S&P 1500",
    "text": "Regressing Apple’s (AAPL) returns against S&P 1500\n\nSubset of 12 months just to illustrate RSS boxes\nThe full set is 72 months of returns. The sample of 12 months is just to illustrate the residual sum of squares (RSS) concept; the squares are less cluttered.\n\ndata_72 &lt;- readRDS(\"t2-20-17-aapl-sp1500.rds\") # 72 monthly returns\nrow.names(data_72) &lt;- 1:nrow(data_72)\nmodel_72 &lt;- lm(r_m_AAPL ~ r_SP_1500, data = data_72) # linear model\n\nset.seed(97531) # Adding Y ~ X just because they're familiar axes\ndata_12 &lt;- sample_n(data_72, 12) # sample of 12 monthly returns \ndata_12$y &lt;- data_12$r_m_AAPL # just to illustrate RSS\ndata_12$x &lt;- data_12$r_SP_1500\n\nmodel_12 &lt;- lm(y ~ x, data=data_12) # linear model\ndata_12$residuals &lt;- residuals(model_12)\n\nsum(model_12$residuals^2)\n\n[1] 0.0448225\n\nRSS &lt;- sum(model_12$residuals^2) \npred_Y &lt;- predict(model_12)\n\n# colors for plots\ngreen_line = \"#3aaf85\"; blue_points = \"#1b6ca8\"; red_color = \"#cd201f\"\n\np1 &lt;- data_12 |&gt; ggplot(aes(x=x, y=y)) +\n    geom_point(size=3, color=blue_points) +\n    geom_smooth(method=\"lm\", se=FALSE, color=green_line) + # Adding regression line\n    theme_minimal() +\n    theme(axis.title = element_blank()) + \n    coord_cartesian(xlim = c(-0.15, 0.05), ylim = c(-0.15, 0.20))\n\np2 &lt;- data_12 |&gt; ggplot(aes(x=x, y=y)) +\n    geom_point(size=3, color=blue_points) +\n    geom_smooth(method=\"lm\", se=FALSE, color=green_line) + \n    # geom_segment(aes(xend=x, yend=y - residuals), color=red_color, linewidth = 1, linetype = \"dashed\") +\n    geom_rect(aes(xmin = x - abs(residuals),\n                  xmax = x, \n                  ymin = ifelse(residuals &gt; 0, y - abs(residuals), y), \n                  ymax = ifelse(residuals &gt; 0, y, y + abs(residuals))), \n              fill=\"purple4\", color=\"purple\", linewidth=0.5, alpha = 0.10) +\n    theme_minimal() +\n    theme(axis.title = element_blank()) + \n    coord_cartesian(xlim = c(-0.15, 0.05), ylim = c(-0.15, 0.20))\n\nscatter_pw &lt;- p1 + p2 \nscatter_pw + plot_annotation(\n    title = \"The OLS line minimizes the residual sum of squares (RSS)\",\n    subtitle = sprintf(\"In ths case, RSS = %.4f\", RSS)\n)\n\n\n\n# To show the residuals in a gt table\nresult_df &lt;- data.frame(\n  X = data_12$x,\n  Y = data_12$y,\n  Pred_Y = pred_Y,\n  residual = model_12$residuals,\n  residual_sq = model_12$residuals^2\n)\n\n# But sorting by X = SP1500 \nresult_df_sorted &lt;- result_df[order(result_df$X), ]\nresult_df_sorted_tbl &lt;- gt(result_df_sorted)\np1_tbl &lt;- result_df_sorted_tbl |&gt; \n    fmt_percent(\n        columns = 1:4,\n        decimals = 2\n    ) |&gt; \n    fmt_number(\n        columns = 5,\n        decimals = 5\n    ) |&gt; \n    cols_label(\n        X = md(\"**S&P 1500**\"),\n        Y = md(\"**AAPL**\"),\n        Pred_Y = md(\"**Pred(AAPL)**\"),\n        residual = md(\"**Residual**\"),\n        residual_sq = md(\"**Residual^2**\")\n    ) |&gt; \n    data_color(\n        columns = 5,\n        palette = c(\"white\",\"purple4\"),\n        domain = c(0,0.02),\n        na_color = \"lightgrey\"\n    ) |&gt; \n    tab_options(\n        table.font.size = 12\n    )\n\np1_tbl\n\n\n\n\n\n  \n    \n    \n      S&P 1500\n      AAPL\n      Pred(AAPL)\n      Residual\n      Residual^2\n    \n  \n  \n    −9.15%\n−12.41%\n−11.61%\n−0.80%\n0.00006\n    −7.60%\n−3.10%\n−9.62%\n6.53%\n0.00426\n    −6.64%\n−13.26%\n−8.38%\n−4.88%\n0.00238\n    0.19%\n−4.36%\n0.40%\n−4.76%\n0.00226\n    0.42%\n0.58%\n0.70%\n−0.12%\n0.00000\n    0.55%\n−1.51%\n0.86%\n−2.37%\n0.00056\n    0.66%\n6.34%\n1.00%\n5.34%\n0.00285\n    1.00%\n−5.89%\n1.44%\n−7.34%\n0.00538\n    2.09%\n6.95%\n2.84%\n4.11%\n0.00169\n    3.18%\n2.76%\n4.25%\n−1.49%\n0.00022\n    3.42%\n18.27%\n4.55%\n13.72%\n0.01883\n    4.37%\n−2.18%\n5.77%\n−7.95%\n0.00632\n  \n  \n  \n\n\n\n\n\n\nThe full dataset of 72 monthly returns\n\nrow.names(data_72) &lt;- 1:nrow(data_72)\nmodel_72 &lt;- lm(r_m_AAPL ~ r_SP_1500, data = data_72)\nmodel_72_coeff &lt;- coef(model_72)\nequation_label &lt;- sprintf(\"Y = %.3fX + %.3f\", model_72_coeff[2], model_72_coeff[1])\n\np1_model_72 &lt;- data_72 %&gt;% ggplot(aes(r_SP_1500, r_m_AAPL)) +\n    geom_point(size = 2, color = blue_points) +\n    geom_smooth(method = \"lm\", color = green_line, fill = \"mediumpurple1\", alpha = 0.20) +\n    theme_minimal() +\n    xlab(\"S&P 1500 return\") +\n    ylab(\"AAPL return\") + \n    annotate(\"text\", x = -0.06, y = 0.15, label = equation_label, \n             size = 5.0, color = \"black\")\n\np1_model_72\n\n\n\nsummary(model_72) # Just to show the standard/typical output\n\n\nCall:\nlm(formula = r_m_AAPL ~ r_SP_1500, data = data_72)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.226290 -0.027060  0.002344  0.040667  0.131313 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.007969   0.007477   1.066     0.29    \nr_SP_1500   1.269625   0.215600   5.889 1.23e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06123 on 70 degrees of freedom\nMultiple R-squared:  0.3313,    Adjusted R-squared:  0.3217 \nF-statistic: 34.68 on 1 and 70 DF,  p-value: 1.23e-07\n\n\n\n\nModel output in gt table\n\nmodel_72_tidy &lt;- tidy(model_72)\ngt_table_model_72 &lt;- gt(model_72_tidy)\n\ngt_table_model_72 &lt;- \n  gt_table_model_72 %&gt;% \n  tab_options(\n    table.font.size = 14\n  ) %&gt;% \n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_body()\n  ) %&gt;% \n  tab_header(\n    title = \"AAPL versus S&P_1500: Gross (incl. Rf) monthly log return\",\n    subtitle = md(\"Six years (2014 - 2019), n = 72 months\")\n  ) %&gt;% \n  tab_source_note(\n    source_note = \"Source: tidyquant https://cran.r-project.org/web/packages/tidyquant/\"\n  ) %&gt;% cols_label(\n    term = \"Coefficient\",\n    estimate = \"Estimate\",\n    std.error = \"Std Error\",\n    statistic = \"t-stat\",\n    p.value = \"p value\"\n  ) %&gt;% fmt_number(\n    columns = vars(estimate, std.error, statistic),\n    decimals = 3\n  ) %&gt;% fmt_scientific(\n    columns = vars(p.value),\n  ) %&gt;% \n  tab_options(\n    heading.title.font.size = 14,\n    heading.subtitle.font.size = 12\n  )\n\ngt_table_model_72\n\n\n\n\n\n  \n    \n      AAPL versus S&P_1500: Gross (incl. Rf) monthly log return\n    \n    \n      Six years (2014 - 2019), n = 72 months\n    \n    \n      Coefficient\n      Estimate\n      Std Error\n      t-stat\n      p value\n    \n  \n  \n    (Intercept)\n0.008\n0.007\n1.066\n2.90 × 10−1\n    r_SP_1500\n1.270\n0.216\n5.889\n1.23 × 10−7\n  \n  \n    \n      Source: tidyquant https://cran.r-project.org/web/packages/tidyquant/\n    \n  \n  \n\n\n\n\nThe table above is featured in one of my practice questions:\n\n\n\n\n\n\nBT Question 20.17.1\n\n\n\nBelow [above] the results of a linear regression analysis are displayed. The dataset is monthly returns over a six-year period; i.e., n = 72 months. The gross returns of Apple’s stock (ticker: AAPL) were regressed against the S&P 1500 Index (the S&P 1500 is our proxy for the market). The explanatory variable is SP_1500 and the response (aka, dependent) variable is AAPL.\nWhich is nearest to the 90.0% confidence interval for the beta of Apple’s (AAPL) stock?\n\n90.0% CI = (0.56; 1.98)\n90.0% CI = (0.70; 1.84)\n90.0% CI = (0.91; 1.63)\n90.0% CI = (-0.004; 0.020)\n\n\n\n\n\n\n\n\n\nAnswer: C. True: 90.0% CI = (0.91; 1.63)\n\n\n\nThe two-tailed critical-Z at 90.0% confidence is 1.645 such that the CI = 1.270 +/- 1.645 × 0.216 = (0.91; 1.63). The confidence interval is given by: coefficient ± (standard error) × (critical value). The sample size is large so we can use the normal deviate of 1.645 associated with 90.0% two-tailed confidence; note this should not require any lookup because we already know the 95.0% confident one-tailed normal deviate is 1.645. With 70 degrees of freedom, the critical t value is T.INV.2T(0.10, 70) = 1.666914, so we can see that normal Z is a close approximation.\n\n\n\n# Confidence interval around the slope\nbeta &lt;- model_72_tidy$estimate[2]\nse_beta &lt;- model_72_tidy$std.error[2]\nci_confidence = 0.90\nz_2s &lt;- qnorm((1 + ci_confidence)/2)\nci_lower &lt;- beta - se_beta*z_2s\nci_upper &lt;- beta + se_beta*z_2s\n\nci_lower\n\n[1] 0.9149948\n\nci_upper\n\n[1] 1.624256"
  },
  {
    "objectID": "posts/regression-simple/index.html#model-diagnostics",
    "href": "posts/regression-simple/index.html#model-diagnostics",
    "title": "Univariate regression",
    "section": "Model diagnostics",
    "text": "Model diagnostics\nThere are many choices but I like the performance package.\n\ncheck_model(model_72, check = c(\"linearity\", \"homogeneity\", \"outliers\", \"qq\"))\n\n\n\n\nIn regard to the above:\n\nLinearity plot; aka, Tukey-Anscombe\nHomogeneity (of variance); aka, scale-location plot\nOutliers (Influential Observations) uses Cook’s distance\nQ-Q plot is test of residual normality\n\nBoth of the first two plots (upper row) can be used to check for heteroscedasticity. The second is supposedly better: by rooting the absolute value, differences are amplified. Notice it’s Y-axis (Homogeneity of Variance) is non-negative such that the “perfect” reference line is nearer to one than zero."
  },
  {
    "objectID": "posts/regression-simple/index.html#autocorrelation-tests",
    "href": "posts/regression-simple/index.html#autocorrelation-tests",
    "title": "Univariate regression",
    "section": "Autocorrelation tests",
    "text": "Autocorrelation tests\nFirst, Durbin-Watson with check_autocorrelation() in performance package:\n\ncheck_autocorrelation(model_72)\n\nOK: Residuals appear to be independent and not autocorrelated (p = 0.068).\n\n\nLet’s plot residual against lag 1 residual.\n\nresiduals_72 &lt;- residuals(model_72)\nlagged_residuals_72 &lt;- c(NA, residuals_72[-length(residuals_72)])\n\nresidual_data &lt;- data.frame(\n  Residuals = residuals_72[-1],  # Exclude the first value as it doesn't have a lagged residual\n  Lagged_Residuals = lagged_residuals_72[-1]  # Exclude the last value as it is NA\n)\n\nggplot(residual_data, aes(x = Lagged_Residuals, y = Residuals)) +\n  geom_point(color = blue_points) +\n  labs(title = \"Scatter Plot of Residuals vs. Lagged Residuals\",\n       x = \"Lagged Residuals (i-1)\",\n       y = \"Residuals (i)\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = green_line) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = green_line) +\n  theme_minimal()\n\n\n\nlinear_model &lt;- lm(Residuals ~ Lagged_Residuals, data = residual_data)\nlinear_model\n\n\nCall:\nlm(formula = Residuals ~ Lagged_Residuals, data = residual_data)\n\nCoefficients:\n     (Intercept)  Lagged_Residuals  \n        0.001015         -0.218861  \n\ncor(residual_data$Residuals, residual_data$Lagged_Residuals)\n\n[1] -0.2207468\n\nsummary(linear_model)$r.squared\n\n[1] 0.04872914\n\ncor(residual_data$Residuals, residual_data$Lagged_Residuals)^2\n\n[1] 0.04872914\n\n\nFinally, let’s try dw.test from the desk package which is new but looks good:\n\ndw.test(model_72, dir = \"left\")\n\n\nDurbin-Watson Test on AR(1) autocorrelation \n--------------------------------------------\n\nHypotheses: \n                              H0:                         H1:\n  d &gt;= 2 (rho &lt;= 0, no pos. a.c.)  d &lt; 2 (rho &gt; 0, pos. a.c.)\n\nTest results: \n      dw  crit.value  p.value  sig.level            H0\n  2.3979      1.6107   0.9589       0.05  not rejected\n\ndw.test(model_72, dir = \"right\")\n\n\nDurbin-Watson Test on AR(1) autocorrelation \n--------------------------------------------\n\nHypotheses: \n                              H0:                         H1:\n  d &lt;= 2 (rho &gt;= 0, no neg. a.c.)  d &gt; 2 (rho &lt; 0, neg. a.c.)\n\nTest results: \n      dw  crit.value  p.value  sig.level        H0\n  2.3979      2.3765   0.0411       0.05  rejected"
  },
  {
    "objectID": "posts/this-quarto-site/index.html",
    "href": "posts/this-quarto-site/index.html",
    "title": "This is a Quarto website",
    "section": "",
    "text": "I want to test-demo Quarto’s capabilities (how-to details are here on my substack). My previous data science blog was this distill site. Specifically, in this post I’d like to show:\n\nHow the openai package can prompt GPT and DALL-E via the API\nHow Quarto is truly multi-language: this page runs both R and python code chunks (even sharing the diamonds_df dataframe)\nHow the gptstudio package enables GPT as a copilot within the RStudio IDE (this is not a Quarto feature per se)\n\n\nPrompting GPT and DALL-E via API\nThe openai package includes create_image() which returns a convenient list that contains a URL of the image. For this post, I only evaluated create_image() once and saved the DALL-E image to a .png file because I don’t like every image; then commented the code. However, the subsequent GPT text prompt (i.e., completion object) is evaluated. In other words, the response to my prompt (“what are likely to be the top three implications of artificial intelligence on edtech?”) is different each time the page is rendered.\n\nSys.setenv(OPENAI_API_KEY = openai_key)\n\nlibrary(openai)\nlibrary(gptstudio)\nlibrary(tidyverse)\n# library(reticulate)\n\nprompt_dalle &lt;- \"Create a high quality background for my laptop with a minimalist landscape of a mountain with forest with multiple sky colors during sunset\"\n\nlandscape &lt;- create_image(prompt_dalle)\nlandscape_url &lt;- landscape$data$url\n\n# destination &lt;- \"mylandscape.png\"\n# download.file(landscape_url, destfile = destination, mode = \"wb\")\n\n\n\n\nlandscape by DALL·E\n\n\nSimilarly, create_chat_completion returns a list. We can easily retrieve the reply:\n\nlibrary(stringr)\nprompt_gpt &lt;- \"what are likely to be the top three implications of artificial intelligence on edtech?\"\nprompt_gpt_chars &lt;- nchar(prompt_gpt)\nprompt_gpt_words &lt;- length(strsplit(prompt_gpt, \"\\\\s+\")[[1]])\n\n# Here is the call to GPT 3.5 with my prompt_gpt text\nreply_gpt &lt;- create_chat_completion(\n    model = \"gpt-3.5-turbo\",\n    messages = list(\n        list(\n            \"role\" = \"user\",\n            \"content\" = prompt_gpt\n        )\n    )\n)\n\n# The response by GPT is a chat completion object that contains an\n# array (list) of choices (can be more than one) including the message.content\nreply_gpt_message &lt;- reply_gpt$choices$message.content\nreply_gpt_chars &lt;- nchar(reply_gpt_message)\nreply_gpt_words &lt;- length(strsplit(reply_gpt_message, \"\\\\s+\")[[1]])\n\ntotal_chars &lt;- prompt_gpt_chars + reply_gpt_chars\ntotal_words &lt;- prompt_gpt_words + reply_gpt_words\ntotal_tokens &lt;- reply_gpt$usage$total_tokens\ntoken_stats_text &lt;- paste(\"Total tokens =\", total_tokens, \n                          \". Given\", total_words, \"words and\", total_chars, \"characters, that's\",\n                          sprintf(\"%.3f\", total_tokens/total_words), \"tokens/word and\",\n                          sprintf(\"%.3f\", total_tokens/total_chars), \"tokens/character.\")\n\nprint(token_stats_text)\n\n[1] \"Total tokens = 302 . Given 241 words and 1822 characters, that's 1.253 tokens/word and 0.166 tokens/character.\"\n\ncat(reply_gpt_message, sep = \"\\n\")\n\nThe top three implications of artificial intelligence (AI) on edtech (education technology) are:\n\n1. Personalized learning: AI has the potential to revolutionize education by enabling personalized learning experiences tailored to the individual needs and abilities of each student. AI-powered systems can analyze vast amounts of data collected from students to identify their strengths, weaknesses, and learning styles, allowing educators to provide customized content, resources, and feedback. This helps students learn at their own pace and in ways that align with their specific requirements.\n\n2. Intelligent tutoring: AI-powered intelligent tutoring systems offer individualized support and guidance to students, mimicking the role of a human tutor. These systems use natural language processing and machine learning algorithms to assess students' knowledge, predict misconceptions, and provide targeted recommendations and explanations. With AI, students can access on-demand assistance and personalized tutoring, which enhances their understanding and academic success.\n\n3. Enhanced administrative processes: AI can streamline administrative tasks and processes within education institutions, freeing up time for educators to focus on teaching. AI-powered tools can automate routine tasks such as grading assessments, generating reports, and managing student records. This automation improves efficiency, reduces administrative burdens, and enables educators to devote more time to instruction and student engagement.\n\nOverall, AI in edtech holds the potential to provide tailored learning experiences, personalized tutoring, and improved administrative efficiency, ultimately enhancing the quality and effectiveness of education.\n\n\n\n\nExecuting a python code block and the sharing the dataframe\nNow I will just load the built-in diamonds dataset and lazily convert the three factor levels (cut, clarity, and color) to integers. But I will skip R’s regression model, lm(), because I am going to let python fit the linear model …\n\ndiamonds_df &lt;- diamonds\ndiamonds_df$cut_int &lt;- as.integer(diamonds_df$cut)\ndiamonds_df$clarity_int &lt;- as.integer(diamonds_df$clarity)\ndiamonds_df$color_int &lt;- as.integer(diamonds_df$color)\n\n# Going to skip lm() in R and let python fit the model!\n# lm_diamonds &lt;- lm(price ~ carat + cut_int + color_int + clarity_int, data = diamonds_df)\n# diamonds_df$residuals &lt;- resid(lm_diamonds)\n# diamonds_df$predictions &lt;- predict(lm_diamonds)\n# diamonds_df |&gt; ggplot(aes(x = predictions, y = residuals)) +\n#   geom_point() +\n#   geom_hline(yintercept = 0, linetype = \"dashed\") +\n#   labs(title = \"Residual Plot\", x = \"Predicted Values\", y = \"Residuals\")\n\n… and here is the python code chunk! This is possible because the first line of the fenced code braces the executable code with “python” per these instructions.. Of course, a python installation is required to render locally.\n\n```{python}\n#| message: false\n\ndiamonds_data_py = r.diamonds_df\n\nimport statsmodels.api as sm\ny = diamonds_data_py[[\"price\"]]\n\nx = diamonds_data_py[[\"carat\", \"cut_int\", \"color_int\", \"clarity_int\"]]\nx = sm.add_constant(x)\nmod = sm.OLS(y, x).fit()\ndiamonds_data_py[\"Predicted\"] = mod.predict(x)\ndiamonds_data_py[\"Residuals\"] = mod.resid\n```\n\nAnd, finally, I will revert back to R to utilize ggplot. As explained by Nicola Rennie the key here is to load the reticulate package so that we can use the py prefix to retrieve the diamonds_data_py object. But you can see: the original R dataframe, diamonds_df, was retreived in python, via diamonds_data_py = r.diamonds_df, and then R retrieved that model via diamonds_residuals &lt;- py$diamonds_data_py. Sweet! But, okay, not the best line we’ve ever fit. That’s why we look at the residuals, after all.\n\nlibrary(reticulate)\nlibrary(ggplot2)\nlibrary(ggthemes)\ndiamonds_residuals &lt;- py$diamonds_data_py\nggplot(data = diamonds_residuals,\n       mapping = aes(x = Predicted,\n                     y = Residuals)) +\n    geom_point(colour = \"#2F4F4F\") +\n    geom_hline(yintercept = 0, colour = \"red\") +\n    theme_economist()\n\n\n\n\n\n\n\n\n\n\nRStudio Co-pilot with gptstudio package\nWhat you can’t easily see on the page is the co-pilot enabled by the gptstudio package. Once the package is installed, I only neeed to setup the API key via the command:\n\nSys.setenv(OPENAI_API_KEY = \"&lt;APIKEY&gt;\")\n\nFor example, below I call for help with this prompt (“generate a ggplot …”)\n\n\n\ngptstudio as co-pilot\n\n\n… and the comment changes to the following:\n\n\n\nchanges the comment to code!\n\n\nIt’s not a great example but instructive. This code requires two quick tweaks in order to work. You do need to know how to write code, but at the same time, co-pilot clearly saves time; e.g., for some analyis, it’s cut the time required in half or better."
  }
]