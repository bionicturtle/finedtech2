{
  "hash": "e103fb028c42cf3d2385cf78d105094b",
  "result": {
    "markdown": "---\ntitle: Clustering with k-means algorithm\ndescription: Unsupervised learning groups observations by feature similarity\nauthor: David Harper, CFA, FRM\ndate: 2023-12-03\ncategories: [code, analysis]\nexecute: \n  echo: true\n  warning: false\n---\n\n\nContents\n\n-   Retrieve stocks and standardize features\n    -   Select features\n-   Elbow method for optimal clusters\n-   K-means clusters\n    -   Visualized\n    -   Unscaled centroids\n\n## Retrive stocks and standardize features\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(corrplot); library(ggcorrplot) # may not use\nlibrary(factoextra) \n\n# source is free trial of S&P https://www.tiingo.com/ \n# This is approximately the S&P1500; i.e, large-, mid- and small-cap stocks\nstocks1500 <- read_csv(\"k-means-set_v1_2.csv\") \n\nstocks1500 <- stocks1500 |> rename(\n    market_cap = 'Market Cap',\n    div_yield = 'Dividend Yield',\n    gross_margin = 'Gross Margin',\n    revenue_growth = 'Revenue Growth (QoQ)',\n    rho_sp500 = 'Correlation to S&P 500',\n    volatility = '1 Year Volatility',\n    pe_ratio = 'P/E Ratio',\n    debt_equity = 'Debt/Equity (D/E) Ratio',\n    ROE = 'Return on Equity (ROE)',\n    ROA = 'Return on Assets (ROA/ROI)',\n    TSR_1year = '1 Year Return',\n    rho_treasury = 'Correlation to U.S. Treasuries',\n    enterprise_value = 'Enterprise Val',\n    pb_ratio = 'P/B Ratio'\n)\n\n# remove outliers, observed ex post\nstocks1500 <- stocks1500 |> filter(Ticker != \"AMZN\")\nstocks1500 <- stocks1500 |> filter(!Ticker %in% c(\"PDD\", \"MELI\", \"NDAQ\", \"RCL\"))\n\n# filtering by market cap: important reduction here!\ndf <- stocks1500 |> filter(market_cap > mean(stocks1500$market_cap))\nnumeric_cols <- df |> select_if(is.numeric)\noptions(scipen = 999)\n\n# because we're going to standardize the features\noriginal_means <- colMeans(numeric_cols)\noriginal_sds <- numeric_cols  |>  map_dbl(sd)\n\nstd_cols <- numeric_cols |> \n  mutate(across(everything(), ~(. - mean(.)) / sd(.)))\n\ndf_std <- df |> \n    select(Ticker, Name, Sector, Industry) |> \n    bind_cols(std_cols)\n```\n:::\n\n\n### Select features\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselected_features <- c(\"volatility\", \"TSR_1year\")\n```\n:::\n\n\n## Elbow method for optimal clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompute_elbow <- function(df, selected_columns) {\n    numeric_data <- select(df, all_of(selected_columns))\n    \n    compute_wss <- function(k) {\n        kmeans_result <- kmeans(numeric_data, centers = k, nstart = 25)\n        kmeans_result$tot.withinss\n    }\n    \n    k_values <- 1:25\n    wss_values <- map_dbl(k_values, compute_wss)\n    \n    elbow_data <- tibble(k = k_values, wss = wss_values)\n\n    # Calculate slopes\n    elbow_data <- elbow_data %>%\n        mutate(slope = c(NA, diff(wss) / diff(k)))\n\n    return(elbow_data)\n}\n\nelbow_data <- compute_elbow(df_std, selected_features)\n\nplot_elbow <- function(elbow_data) {\n    ggplot(elbow_data, aes(x = k, y = wss)) +\n        geom_line() +\n        geom_point() +\n        geom_text(aes(label = round(slope, 1)), vjust = -1.5) +\n        theme_minimal() +\n        labs(title = \"Elbow Method for Optimal Number of Clusters\",\n             x = \"Number of Clusters (k)\", \n             y = \"Total Within-Cluster Sum of Squares\")\n}\n\n# Use the function with your data\nelbow_plot <- plot_elbow(elbow_data)\n\n# Display the plot\nprint(elbow_plot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n## K-means clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(9367) # Set a random seed for reproducibility\n\n# Color palette\n# location (ex post): top-middle, bottom-middle, bottom-right, left, top-right\ncustom_colors <- c(\"blue1\", \"darkorange1\", \"firebrick3\", \"cyan3\", \"springgreen3\")\n\nnumeric_data <- df_std |> select(all_of(selected_features))\n\n# based on the elbow method's so-called \n# elbow point but ultimately is discretionary\nnum_clusters <- 5 \n\nkmeans_result_n <- kmeans(numeric_data, centers = num_clusters, nstart = 25)\n\n# Print out the results\nprint(kmeans_result_n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nK-means clustering with 5 clusters of sizes 68, 69, 30, 85, 30\n\nCluster means:\n  volatility  TSR_1year\n1 -0.1663365  0.6846281\n2  0.0751603 -0.6467280\n3  1.7067078 -0.1904547\n4 -0.9749478 -0.6417393\n5  1.2598050  1.9443669\n\nClustering vector:\n  [1] 1 5 1 1 1 4 1 4 2 4 5 1 4 5 3 2 1 1 4 4 4 2 4 1 4 1 4 1 2 2 4 1 2 1 2 2 2\n [38] 5 2 4 1 3 4 4 2 3 4 1 2 2 5 4 2 2 5 2 4 4 2 2 4 4 2 1 2 4 2 1 2 4 4 2 2 4\n [75] 2 2 4 5 1 5 4 2 4 1 5 4 4 4 2 5 1 2 4 4 1 5 4 4 2 4 1 4 1 1 5 2 5 2 1 3 1\n[112] 4 3 3 4 2 2 4 4 4 4 5 4 2 1 5 5 4 4 5 1 3 2 1 4 1 2 4 1 1 2 1 1 3 4 1 1 1\n[149] 3 3 3 1 2 3 5 1 4 1 1 4 2 4 1 5 1 4 2 4 1 3 2 4 3 2 3 4 1 2 3 3 1 4 4 3 4\n[186] 5 1 3 2 2 3 3 3 1 1 2 4 3 4 2 2 4 1 4 2 4 4 2 4 4 4 5 1 1 2 2 2 2 4 4 3 1\n[223] 4 3 1 1 4 1 3 1 5 3 1 3 4 2 2 1 5 5 4 5 4 4 2 2 4 2 1 1 2 2 4 4 4 2 3 1 5\n[260] 1 2 1 2 1 4 3 2 1 5 1 5 4 2 5 2 4 2 5 4 4 1 4\n\nWithin cluster sum of squares by cluster:\n[1] 29.48504 27.95429 21.43397 27.33563 27.48363\n (between_SS / total_SS =  76.2 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n```\n:::\n\n```{.r .cell-code}\n# attach cluster membership back to the original data\ndf_std$cluster <- kmeans_result_n$cluster\ndf$cluster <- kmeans_result_n$cluster\n\n# Calculate mean and standard deviation for each feature, grouped by cluster\ncluster_summary <- df |> \n  group_by(cluster) |> \n  summarise(across(everything(),\n                   list(mean = ~mean(.), sd = ~sd(.)), \n                   .names = \"{.col}_{.fn}\"))\n\n# View the results: below instead\n# cluster_summary$volatility_mean\n# cluster_summary$volatility_sd\n# cluster_summary$TSR_1year_mean\n# cluster_summary$TSR_1year_sd\n\n# cross_tab <- table(df_std$Sector, kmeans_result_n$cluster)\ntable(df_std$Sector, kmeans_result_n$cluster)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        \n                          1  2  3  4  5\n  Basic Materials         6  4  3  1  2\n  Communication Services  3  3  0  3  0\n  Consumer Cyclical       4  2  4  0  4\n  Consumer Defensive      2  8  1 13  0\n  Discretionary           0  1  0  0  0\n  Energy                  9  4 13  4  2\n  Financial Services     12 18  3 10  7\n  Healthcare              3  4  0 17  1\n  Industrials            14  8  0 17  4\n  Real Estate             3  4  0  3  0\n  Technology             10  7  6  3 10\n  Unknown                 1  0  0  1  0\n  Unknown Sector          1  3  0  1  0\n  Utilities               0  3  0 12  0\n```\n:::\n:::\n\n\n### Visualized\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plotting\nggplot(df_std, aes(x = volatility, y = TSR_1year, color = as.factor(cluster))) +\n    geom_point() +  # Add points\n    stat_ellipse(type = \"norm\", level = 0.95) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +\n    scale_color_manual(values = custom_colors) +  # Use custom color palette\n    theme_minimal() +  # Minimal theme\n    labs(color = \"Cluster\", \n         title = \"K-means clustering with only 2 features\",\n         subtitle = \"Features are scaled\",\n         x = \"Volatility\", \n         y = \"1 year TRS (TSR_1year) \")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmodel_lm <- lm(TSR_1year ~ volatility, data = df_std)\ncorr <- cor(df_std$TSR_1year, df_std$volatility)\n```\n:::\n\n\n### Unscaled centroids\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselected_means <- original_means[selected_features]\nselected_sds <- original_sds[selected_features]\n\nscaled_centroids <- kmeans_result_n$centers\n\n# Element-wise multiplication of each column by the corresponding standard deviation\n# Then, addition of each column by the corresponding mean\nunscaled_centroids <- sweep(scaled_centroids, 2, selected_sds, FUN = \"*\")\nunscaled_centroids <- sweep(unscaled_centroids, 2, selected_means, FUN = \"+\")\n\nunscaled_centroids_df <- as.data.frame(unscaled_centroids)\nrownames(unscaled_centroids_df) <- paste(\"Cluster\", 1:nrow(unscaled_centroids_df))\n\n# sort by volatility\nunscaled_centroids_df <- unscaled_centroids_df[order(unscaled_centroids_df$volatility), ]\n\nprint(unscaled_centroids_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          volatility   TSR_1year\nCluster 4  0.2438719 -0.04716554\nCluster 1  0.3173974  0.26064020\nCluster 2  0.3393562 -0.04832325\nCluster 5  0.4470738  0.55298364\nCluster 3  0.4877098  0.05756260\n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}