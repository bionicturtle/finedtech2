{
  "hash": "03775f1944bd00bf8dc024e6694f6e23",
  "result": {
    "markdown": "---\ntitle: \"This is a Quarto website\"\ndescription: Posit's brilliant system executes either R or python code (and a GPT API example) \nauthor: David Harper\ndate: 2023-09-15\ncategories: [code, analysis]\nexecute: \n  echo: true\n  warning: false\n---\n\n\nThis is a demonstration post. Now that I've published this Quarto website (details here TBD), I wanted to test (and show) two capabilities:\n\n* The openai package can prompt GPT and DALL-E via the API\n* Quarto can also run python code chunks (referring to dataframes defined in R)\n\n\n\n::: {.cell}\n\n:::\n\n\n### Prompting GPT and DALL-E via API\n\nThe [openai package](https://github.com/irudnyts/openai) includes [create_image()](https://platform.openai.com/docs/api-reference/images) which returns a convenient list that contains a URL of the image. For this post, I only evaluated create_image() once and saved the DALL-E image to a .png file; then commented the code. However, the subsequent GPT text prompt (i.e., completion object) is evaluated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(OPENAI_API_KEY = openai_key)\n\nlibrary(openai)\nlibrary(gptstudio)\nlibrary(tidyverse)\n# library(reticulate)\n\nprompt_dalle <- \"Create a high quality background for my laptop with a minimalist landscape of a mountain with forest with multiple sky colors during sunset\"\n\n# landscape <- create_image(prompt_dalle)\n# landscape_url <- landscape$data$url\n# destination <- \"mylandscape.png\"\n# download.file(landscape_url, destfile = destination, mode = \"wb\")\n```\n:::\n\n\n![landscape by DALLÂ·E](mylandscape.png){width=300 fig-align=\"left\"}\n\nSimilarly, [create_chat_completion](https://platform.openai.com/docs/api-reference/chat/create) returns a list. We can easily retrieve the reply:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stringr)\nprompt_gpt <- \"what are likely to be the top three implications of artificial intelligence on edtech?\"\nprompt_gpt_chars <- nchar(prompt_gpt)\nprompt_gpt_words <- length(strsplit(prompt_gpt, \"\\\\s+\")[[1]])\n\n# Here is the call to GPT 3.5 with my prompt_gpt text\nreply_gpt <- create_chat_completion(\n    model = \"gpt-3.5-turbo\",\n    messages = list(\n        list(\n            \"role\" = \"user\",\n            \"content\" = prompt_gpt\n        )\n    )\n)\n\n# The response by GPT is a chat completion object that contains an\n# array (list) of choices (can be more than one) including the message.content\nreply_gpt_message <- reply_gpt$choices$message.content\nreply_gpt_chars <- nchar(reply_gpt_message)\nreply_gpt_words <- length(strsplit(reply_gpt_message, \"\\\\s+\")[[1]])\n\ntotal_chars <- prompt_gpt_chars + reply_gpt_chars\ntotal_words <- prompt_gpt_words + reply_gpt_words\ntotal_tokens <- reply_gpt$usage$total_tokens\ntoken_stats_text <- paste(\"Total tokens =\", total_tokens, \n                          \". Given\", total_words, \"words and\", total_chars, \"characters, that's\",\n                          sprintf(\"%.3f\", total_tokens/total_words), \"tokens/word and\",\n                          sprintf(\"%.3f\", total_tokens/total_chars), \"tokens/character.\")\n\nprint(token_stats_text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Total tokens = 272 . Given 217 words and 1600 characters, that's 1.253 tokens/word and 0.170 tokens/character.\"\n```\n:::\n\n```{.r .cell-code}\ncat(reply_gpt_message, sep = \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe top three implications of artificial intelligence (AI) on edtech are:\n\n1. Personalized Learning: AI enables the development of adaptive learning systems that provide personalized education experiences to students. By analyzing individual learning patterns, AI can tailor curriculum, pace, and content according to the needs of each student. This could lead to improved learning outcomes, higher student engagement, and reduced knowledge gaps.\n\n2. Intelligent Assessment and Feedback: AI can play a crucial role in automating and enhancing the assessment process. With AI-powered tools, teachers can provide faster and more detailed feedback to students, enabling them to identify areas of improvement. Automated grading systems can also alleviate teachers' workload, freeing up their time for more personalized interactions with students.\n\n3. Data-driven Decision Making: AI helps in collecting, analyzing, and utilizing vast amounts of data generated in educational settings. By analyzing student performance data, educators can gain insights into learning trends, identifying knowledge gaps, and making data-driven decisions to improve teaching practices and curriculum design. AI-driven analytics can assist both teachers and administrators in identifying areas of improvement and implementing evidence-based interventions.\n\nOverall, AI in edtech has the potential to enhance personalized learning experiences, automate assessments, and support data-driven decision making for improved educational outcomes.\n```\n:::\n:::\n\n\n### Executing a python code block and the sharing the dataframe\n\nNow I will just load the built-in [diamonds dataset](https://ggplot2.tidyverse.org/reference/diamonds.html) and lazily convert the three factor levels (cut, clarity, and color) to integers. But I will skip R's regression model, lm(), because I am going to let python fit the linear model ...\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds_df <- diamonds\ndiamonds_df$cut_int <- as.integer(diamonds_df$cut)\ndiamonds_df$clarity_int <- as.integer(diamonds_df$clarity)\ndiamonds_df$color_int <- as.integer(diamonds_df$color)\n\n# Going to skip lm() in R and let python fit the model!\n# lm_diamonds <- lm(price ~ carat + cut_int + color_int + clarity_int, data = diamonds_df)\n# diamonds_df$residuals <- resid(lm_diamonds)\n# diamonds_df$predictions <- predict(lm_diamonds)\n# diamonds_df |> ggplot(aes(x = predictions, y = residuals)) +\n#   geom_point() +\n#   geom_hline(yintercept = 0, linetype = \"dashed\") +\n#   labs(title = \"Residual Plot\", x = \"Predicted Values\", y = \"Residuals\")\n```\n:::\n\n\n... and here is the python code chunk! This is possible because the *first line of the fenced code* braces the executable code with \"python\" [per these instructions.](https://quarto.org/docs/computations/python.html). Of course, a python installation is required to render locally.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{python}}\n#| message: false\n\ndiamonds_data_py = r.diamonds_df\n\nimport statsmodels.api as sm\ny = diamonds_data_py[[\"price\"]]\n\nx = diamonds_data_py[[\"carat\", \"cut_int\", \"color_int\", \"clarity_int\"]]\nx = sm.add_constant(x)\nmod = sm.OLS(y, x).fit()\ndiamonds_data_py[\"Predicted\"] = mod.predict(x)\ndiamonds_data_py[\"Residuals\"] = mod.resid\n```\n````\n:::\n\n\nAnd, finally, I will revert back to R to utilize ggplot. As [explained by Nicola Rennie](https://nrennie.rbind.io/blog/combining-r-and-python-with-reticulate-and-quarto/) the key here is to load the reticulate package so that we can use the **py** prefix to retrieve the diamonds_data_py object. But you can see: the original R dataframe, **diamonds_df**, was retreived in python, via **diamonds_data_py = r.diamonds_df**, and then R retrieved that model via **diamonds_residuals <- py$diamonds_data_py**. Sweet!\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(ggplot2)\nlibrary(ggthemes)\ndiamonds_residuals <- py$diamonds_data_py\nggplot(data = diamonds_residuals,\n       mapping = aes(x = Predicted,\n                     y = Residuals)) +\n    geom_point(colour = \"#2F4F4F\") +\n    geom_hline(yintercept = 0, colour = \"red\") +\n    theme_economist()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plotting-1.png){fig-align='left' fig-alt='Scatter plot of predicted and residual values for the fitted linear model.' width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}