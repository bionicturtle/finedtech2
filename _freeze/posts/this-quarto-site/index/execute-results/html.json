{
  "hash": "6464f9db2c758994d7f8dfc28b29454d",
  "result": {
    "markdown": "---\ntitle: \"This is a Quarto website\"\ndescription: Posit's brilliant system executes either R or python code (and a GPT API example) \nauthor: David Harper\ndate: 2023-09-15\ncategories: [code, analysis]\nexecute: \n  echo: true\n  warning: false\n---\n\n\nI want to test-demo Quarto's capabilities (how-to details are here on my substack). My previous data science blog was [this distill site](https://dh-data.org/). Specifically, in this post I'd like to show:\n\n-   How the openai package can prompt GPT and DALL-E via the API\n-   How Quarto is truly *multi-language*: this page runs both R and python code chunks (even sharing the diamonds_df dataframe)\n-   How the [gptstudio package](https://github.com/MichelNivard/gptstudio) enables GPT as a copilot within the RStudio IDE (this is not a Quarto feature per se)\n\n\n::: {.cell}\n\n:::\n\n\n### Prompting GPT and DALL-E via API\n\nThe [openai package](https://github.com/irudnyts/openai) includes [create_image()](https://platform.openai.com/docs/api-reference/images) which returns a convenient list that contains a URL of the image. For this post, I only evaluated create_image() once and saved the DALL-E image to a .png file because I don't like every image; then commented the code. However, the subsequent GPT text prompt (i.e., completion object) is evaluated. In other words, the response to my prompt (\"what are likely to be the top three implications of artificial intelligence on edtech?\") is different each time the page is rendered.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(OPENAI_API_KEY = openai_key)\n\nlibrary(openai)\nlibrary(gptstudio)\nlibrary(tidyverse)\n# library(reticulate)\n\nprompt_dalle <- \"Create a high quality background for my laptop with a minimalist landscape of a mountain with forest with multiple sky colors during sunset\"\n\nlandscape <- create_image(prompt_dalle)\nlandscape_url <- landscape$data$url\n\n# destination <- \"mylandscape.png\"\n# download.file(landscape_url, destfile = destination, mode = \"wb\")\n```\n:::\n\n\n![landscape by DALLÂ·E](mylandscape.png){width=\"300\" fig-align=\"left\"}\n\nSimilarly, [create_chat_completion](https://platform.openai.com/docs/api-reference/chat/create) returns a list. We can easily retrieve the reply:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stringr)\nprompt_gpt <- \"what are likely to be the top three implications of artificial intelligence on edtech?\"\nprompt_gpt_chars <- nchar(prompt_gpt)\nprompt_gpt_words <- length(strsplit(prompt_gpt, \"\\\\s+\")[[1]])\n\n# Here is the call to GPT 3.5 with my prompt_gpt text\nreply_gpt <- create_chat_completion(\n    model = \"gpt-3.5-turbo\",\n    messages = list(\n        list(\n            \"role\" = \"user\",\n            \"content\" = prompt_gpt\n        )\n    )\n)\n\n# The response by GPT is a chat completion object that contains an\n# array (list) of choices (can be more than one) including the message.content\nreply_gpt_message <- reply_gpt$choices$message.content\nreply_gpt_chars <- nchar(reply_gpt_message)\nreply_gpt_words <- length(strsplit(reply_gpt_message, \"\\\\s+\")[[1]])\n\ntotal_chars <- prompt_gpt_chars + reply_gpt_chars\ntotal_words <- prompt_gpt_words + reply_gpt_words\ntotal_tokens <- reply_gpt$usage$total_tokens\ntoken_stats_text <- paste(\"Total tokens =\", total_tokens, \n                          \". Given\", total_words, \"words and\", total_chars, \"characters, that's\",\n                          sprintf(\"%.3f\", total_tokens/total_words), \"tokens/word and\",\n                          sprintf(\"%.3f\", total_tokens/total_chars), \"tokens/character.\")\n\nprint(token_stats_text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Total tokens = 302 . Given 241 words and 1822 characters, that's 1.253 tokens/word and 0.166 tokens/character.\"\n```\n:::\n\n```{.r .cell-code}\ncat(reply_gpt_message, sep = \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe top three implications of artificial intelligence (AI) on edtech (education technology) are:\n\n1. Personalized learning: AI has the potential to revolutionize education by enabling personalized learning experiences tailored to the individual needs and abilities of each student. AI-powered systems can analyze vast amounts of data collected from students to identify their strengths, weaknesses, and learning styles, allowing educators to provide customized content, resources, and feedback. This helps students learn at their own pace and in ways that align with their specific requirements.\n\n2. Intelligent tutoring: AI-powered intelligent tutoring systems offer individualized support and guidance to students, mimicking the role of a human tutor. These systems use natural language processing and machine learning algorithms to assess students' knowledge, predict misconceptions, and provide targeted recommendations and explanations. With AI, students can access on-demand assistance and personalized tutoring, which enhances their understanding and academic success.\n\n3. Enhanced administrative processes: AI can streamline administrative tasks and processes within education institutions, freeing up time for educators to focus on teaching. AI-powered tools can automate routine tasks such as grading assessments, generating reports, and managing student records. This automation improves efficiency, reduces administrative burdens, and enables educators to devote more time to instruction and student engagement.\n\nOverall, AI in edtech holds the potential to provide tailored learning experiences, personalized tutoring, and improved administrative efficiency, ultimately enhancing the quality and effectiveness of education.\n```\n:::\n:::\n\n\n### Executing a python code block and the sharing the dataframe\n\nNow I will just load the built-in [diamonds dataset](https://ggplot2.tidyverse.org/reference/diamonds.html) and lazily convert the three factor levels (cut, clarity, and color) to integers. But I will skip R's regression model, lm(), because I am going to let python fit the linear model ...\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds_df <- diamonds\ndiamonds_df$cut_int <- as.integer(diamonds_df$cut)\ndiamonds_df$clarity_int <- as.integer(diamonds_df$clarity)\ndiamonds_df$color_int <- as.integer(diamonds_df$color)\n\n# Going to skip lm() in R and let python fit the model!\n# lm_diamonds <- lm(price ~ carat + cut_int + color_int + clarity_int, data = diamonds_df)\n# diamonds_df$residuals <- resid(lm_diamonds)\n# diamonds_df$predictions <- predict(lm_diamonds)\n# diamonds_df |> ggplot(aes(x = predictions, y = residuals)) +\n#   geom_point() +\n#   geom_hline(yintercept = 0, linetype = \"dashed\") +\n#   labs(title = \"Residual Plot\", x = \"Predicted Values\", y = \"Residuals\")\n```\n:::\n\n\n... and here is the python code chunk! This is possible because the *first line of the fenced code* braces the executable code with \"python\" [per these instructions.](https://quarto.org/docs/computations/python.html). Of course, a python installation is required to render locally.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{python}}\n#| message: false\n\ndiamonds_data_py = r.diamonds_df\n\nimport statsmodels.api as sm\ny = diamonds_data_py[[\"price\"]]\n\nx = diamonds_data_py[[\"carat\", \"cut_int\", \"color_int\", \"clarity_int\"]]\nx = sm.add_constant(x)\nmod = sm.OLS(y, x).fit()\ndiamonds_data_py[\"Predicted\"] = mod.predict(x)\ndiamonds_data_py[\"Residuals\"] = mod.resid\n```\n````\n:::\n\n\nAnd, finally, I will revert back to R to utilize ggplot. As [explained by Nicola Rennie](https://nrennie.rbind.io/blog/combining-r-and-python-with-reticulate-and-quarto/) the key here is to load the reticulate package so that we can use the **py** prefix to retrieve the diamonds_data_py object. But you can see: the original R dataframe, **diamonds_df**, was retreived in python, via **diamonds_data_py = r.diamonds_df**, and then R retrieved that model via **diamonds_residuals \\<- py\\$diamonds_data_py**. Sweet! But, okay, not the best line we've ever fit. That's why we look at the residuals, after all.\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(ggplot2)\nlibrary(ggthemes)\ndiamonds_residuals <- py$diamonds_data_py\nggplot(data = diamonds_residuals,\n       mapping = aes(x = Predicted,\n                     y = Residuals)) +\n    geom_point(colour = \"#2F4F4F\") +\n    geom_hline(yintercept = 0, colour = \"red\") +\n    theme_economist()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plotting-1.png){fig-align='left' fig-alt='Scatter plot of predicted and residual values for the fitted linear model.' width=672}\n:::\n:::\n\n\n### RStudio Co-pilot with gptstudio package\n\nWhat you can't easily see on the page is the co-pilot enabled by the [gptstudio package](https://github.com/MichelNivard/gptstudio). Once the package is installed, I only neeed to setup the API key via the command:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(OPENAI_API_KEY = \"<APIKEY>\")\n```\n:::\n\n\nFor example, below I call for help with this prompt (\"generate a ggplot ...\")\n\n![gptstudio as co-pilot](gptstudio-first.png) \n\n... and the comment changes to the following:\n\n![changes the comment to code!](gptstudio-second.png)\n\nIt's not a great example but instructive. This code requires two quick tweaks in order to work. You do need to know how to write code, but at the same time, co-pilot clearly saves time; e.g., for some analyis, it's cut the time required in half or better. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}