{
  "hash": "a976a710baa980c9c90f44173b9a4060",
  "result": {
    "markdown": "---\ntitle: \"This is a Quarto website\"\ndescription: Posit's brilliant system executes either R or python code (and a GPT API example) \nauthor: David Harper\ndate: 2023-09-15\ncategories: [code, analysis]\nexecute: \n  echo: true\n  warning: false\n---\n\n\nThis is a demonstration post. Now that I've published this Quarto website (details here TBD, itself a switch from [my distill site here](https://dh-data.org/), I wanted to test (and show) two capabilities:\n\n* The openai package can prompt GPT and DALL-E via the API\n* Quarto can also run python code chunks (referring to dataframes defined in R)\n\n\n\n::: {.cell}\n\n:::\n\n\n### Prompting GPT and DALL-E via API\n\nThe [openai package](https://github.com/irudnyts/openai) includes [create_image()](https://platform.openai.com/docs/api-reference/images) which returns a convenient list that contains a URL of the image. For this post, I only evaluated create_image() once and saved the DALL-E image to a .png file; then commented the code. However, the subsequent GPT text prompt (i.e., completion object) is evaluated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(OPENAI_API_KEY = openai_key)\n\nlibrary(openai)\nlibrary(gptstudio)\nlibrary(tidyverse)\n# library(reticulate)\n\nprompt_dalle <- \"Create a high quality background for my laptop with a minimalist landscape of a mountain with forest with multiple sky colors during sunset\"\n\n# landscape <- create_image(prompt_dalle)\n# landscape_url <- landscape$data$url\n# destination <- \"mylandscape.png\"\n# download.file(landscape_url, destfile = destination, mode = \"wb\")\n```\n:::\n\n\n![landscape by DALLÂ·E](mylandscape.png){width=300 fig-align=\"left\"}\n\nSimilarly, [create_chat_completion](https://platform.openai.com/docs/api-reference/chat/create) returns a list. We can easily retrieve the reply:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stringr)\nprompt_gpt <- \"what are likely to be the top three implications of artificial intelligence on edtech?\"\nprompt_gpt_chars <- nchar(prompt_gpt)\nprompt_gpt_words <- length(strsplit(prompt_gpt, \"\\\\s+\")[[1]])\n\n# Here is the call to GPT 3.5 with my prompt_gpt text\nreply_gpt <- create_chat_completion(\n    model = \"gpt-3.5-turbo\",\n    messages = list(\n        list(\n            \"role\" = \"user\",\n            \"content\" = prompt_gpt\n        )\n    )\n)\n\n# The response by GPT is a chat completion object that contains an\n# array (list) of choices (can be more than one) including the message.content\nreply_gpt_message <- reply_gpt$choices$message.content\nreply_gpt_chars <- nchar(reply_gpt_message)\nreply_gpt_words <- length(strsplit(reply_gpt_message, \"\\\\s+\")[[1]])\n\ntotal_chars <- prompt_gpt_chars + reply_gpt_chars\ntotal_words <- prompt_gpt_words + reply_gpt_words\ntotal_tokens <- reply_gpt$usage$total_tokens\ntoken_stats_text <- paste(\"Total tokens =\", total_tokens, \n                          \". Given\", total_words, \"words and\", total_chars, \"characters, that's\",\n                          sprintf(\"%.3f\", total_tokens/total_words), \"tokens/word and\",\n                          sprintf(\"%.3f\", total_tokens/total_chars), \"tokens/character.\")\n\nprint(token_stats_text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Total tokens = 217 . Given 173 words and 1314 characters, that's 1.254 tokens/word and 0.165 tokens/character.\"\n```\n:::\n\n```{.r .cell-code}\ncat(reply_gpt_message, sep = \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1. Personalized Learning: Artificial intelligence (AI) can enable highly personalized learning experiences by analyzing individual student behaviors, needs, and strengths. AI algorithms can adapt the educational content and pace of learning to meet the unique requirements of each student, thus enhancing their learning outcomes.\n\n2. Intelligent Tutoring Systems: AI-powered intelligent tutoring systems can provide immediate, personalized feedback and guidance to learners. These systems can analyze student responses, identify their misconceptions, and offer tailored explanations or additional resources. This technology can greatly enhance the effectiveness of online education platforms, enabling more individualized and efficient learning.\n\n3. Automation and Administrative Support: AI has the potential to improve administrative tasks in education. Intelligent chatbots can be used to provide immediate assistance to students regarding inquiries, enrollment, scheduling, or even simple academic tasks. Additionally, AI can automate grading to save teachers' time and provide students with faster feedback. This automation would allow teachers to focus more on individual instruction and personalized learning experiences.\n```\n:::\n:::\n\n\n### Executing a python code block and the sharing the dataframe\n\nNow I will just load the built-in [diamonds dataset](https://ggplot2.tidyverse.org/reference/diamonds.html) and lazily convert the three factor levels (cut, clarity, and color) to integers. But I will skip R's regression model, lm(), because I am going to let python fit the linear model ...\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds_df <- diamonds\ndiamonds_df$cut_int <- as.integer(diamonds_df$cut)\ndiamonds_df$clarity_int <- as.integer(diamonds_df$clarity)\ndiamonds_df$color_int <- as.integer(diamonds_df$color)\n\n# Going to skip lm() in R and let python fit the model!\n# lm_diamonds <- lm(price ~ carat + cut_int + color_int + clarity_int, data = diamonds_df)\n# diamonds_df$residuals <- resid(lm_diamonds)\n# diamonds_df$predictions <- predict(lm_diamonds)\n# diamonds_df |> ggplot(aes(x = predictions, y = residuals)) +\n#   geom_point() +\n#   geom_hline(yintercept = 0, linetype = \"dashed\") +\n#   labs(title = \"Residual Plot\", x = \"Predicted Values\", y = \"Residuals\")\n```\n:::\n\n\n... and here is the python code chunk! This is possible because the *first line of the fenced code* braces the executable code with \"python\" [per these instructions.](https://quarto.org/docs/computations/python.html). Of course, a python installation is required to render locally.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{python}}\n#| message: false\n\ndiamonds_data_py = r.diamonds_df\n\nimport statsmodels.api as sm\ny = diamonds_data_py[[\"price\"]]\n\nx = diamonds_data_py[[\"carat\", \"cut_int\", \"color_int\", \"clarity_int\"]]\nx = sm.add_constant(x)\nmod = sm.OLS(y, x).fit()\ndiamonds_data_py[\"Predicted\"] = mod.predict(x)\ndiamonds_data_py[\"Residuals\"] = mod.resid\n```\n````\n:::\n\n\nAnd, finally, I will revert back to R to utilize ggplot. As [explained by Nicola Rennie](https://nrennie.rbind.io/blog/combining-r-and-python-with-reticulate-and-quarto/) the key here is to load the reticulate package so that we can use the **py** prefix to retrieve the diamonds_data_py object. But you can see: the original R dataframe, **diamonds_df**, was retreived in python, via **diamonds_data_py = r.diamonds_df**, and then R retrieved that model via **diamonds_residuals <- py$diamonds_data_py**. Sweet!\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(ggplot2)\nlibrary(ggthemes)\ndiamonds_residuals <- py$diamonds_data_py\nggplot(data = diamonds_residuals,\n       mapping = aes(x = Predicted,\n                     y = Residuals)) +\n    geom_point(colour = \"#2F4F4F\") +\n    geom_hline(yintercept = 0, colour = \"red\") +\n    theme_economist()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plotting-1.png){fig-align='left' fig-alt='Scatter plot of predicted and residual values for the fitted linear model.' width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}